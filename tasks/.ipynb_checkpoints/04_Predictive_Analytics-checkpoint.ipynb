{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tasks\" data-toc-modified-id=\"Tasks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tasks</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#List-available-GPUs\" data-toc-modified-id=\"List-available-GPUs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>List available GPUs</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Transformations\" data-toc-modified-id=\"Data-Transformations-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Data Transformations</a></span></li><li><span><a href=\"#Test/Train-split-Techniques\" data-toc-modified-id=\"Test/Train-split-Techniques-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Test/Train split Techniques</a></span></li></ul></li><li><span><a href=\"#Additional-Pre-Processing\" data-toc-modified-id=\"Additional-Pre-Processing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Additional Pre-Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deploy-One-Hot-Encoding\" data-toc-modified-id=\"Deploy-One-Hot-Encoding-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Deploy One-Hot-Encoding</a></span></li><li><span><a href=\"#Create-Feature_Sets\" data-toc-modified-id=\"Create-Feature_Sets-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Create Feature_Sets</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machines\" data-toc-modified-id=\"Support-Vector-Machines-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Support Vector Machines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Perform-Grid-search\" data-toc-modified-id=\"Perform-Grid-search-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Perform Grid search</a></span></li><li><span><a href=\"#Train-the-models-with-different-time/spatial\" data-toc-modified-id=\"Train-the-models-with-different-time/spatial-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Train the models with different time/spatial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Batch-Split-k-fold-Cross-Validation\" data-toc-modified-id=\"Batch-Split-k-fold-Cross-Validation-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Batch Split k-fold Cross Validation</a></span></li><li><span><a href=\"#Sliding-Window-cross-Validation\" data-toc-modified-id=\"Sliding-Window-cross-Validation-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Sliding Window cross Validation</a></span></li><li><span><a href=\"#Expanding-Window-Split\" data-toc-modified-id=\"Expanding-Window-Split-7.2.3\"><span class=\"toc-item-num\">7.2.3&nbsp;&nbsp;</span>Expanding Window Split</a></span></li><li><span><a href=\"#Start-End-Split\" data-toc-modified-id=\"Start-End-Split-7.2.4\"><span class=\"toc-item-num\">7.2.4&nbsp;&nbsp;</span>Start End Split</a></span></li></ul></li><li><span><a href=\"#Compare-the-results-of-the-different-time/spaitla-bin-combinations\" data-toc-modified-id=\"Compare-the-results-of-the-different-time/spaitla-bin-combinations-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Compare the results of the different time/spaitla bin combinations</a></span></li><li><span><a href=\"#Analyize-the-models-with-XAI-methods\" data-toc-modified-id=\"Analyize-the-models-with-XAI-methods-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Analyize the models with XAI methods</a></span></li></ul></li><li><span><a href=\"#Neural-Networks\" data-toc-modified-id=\"Neural-Networks-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Train-the-models-with-different-time/spatial-bins-and-different-test/train-spilt-techniques\" data-toc-modified-id=\"Train-the-models-with-different-time/spatial-bins-and-different-test/train-spilt-techniques-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Train the models with different time/spatial bins and different test/train spilt techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Batch-Split-k-fold-Cross-Validation\" data-toc-modified-id=\"Batch-Split-k-fold-Cross-Validation-8.2.1\"><span class=\"toc-item-num\">8.2.1&nbsp;&nbsp;</span>Batch Split k-fold Cross Validation</a></span></li><li><span><a href=\"#Sliding-Window-cross-Validation\" data-toc-modified-id=\"Sliding-Window-cross-Validation-8.2.2\"><span class=\"toc-item-num\">8.2.2&nbsp;&nbsp;</span>Sliding Window cross Validation</a></span></li><li><span><a href=\"#Expanding-Window-Split\" data-toc-modified-id=\"Expanding-Window-Split-8.2.3\"><span class=\"toc-item-num\">8.2.3&nbsp;&nbsp;</span>Expanding Window Split</a></span></li><li><span><a href=\"#Start-End-Split\" data-toc-modified-id=\"Start-End-Split-8.2.4\"><span class=\"toc-item-num\">8.2.4&nbsp;&nbsp;</span>Start End Split</a></span></li></ul></li><li><span><a href=\"#Compare-the-results-of--the-different-time/spaitla-bin-combinations\" data-toc-modified-id=\"Compare-the-results-of--the-different-time/spaitla-bin-combinations-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Compare the results of  the different time/spaitla bin combinations</a></span></li><li><span><a href=\"#Compare-the-different-test/train-split-techniques\" data-toc-modified-id=\"Compare-the-different-test/train-split-techniques-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Compare the different test/train split techniques</a></span></li><li><span><a href=\"#Aanalyize-the-models-with-XAI-methods\" data-toc-modified-id=\"Aanalyize-the-models-with-XAI-methods-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>Aanalyize the models with XAI methods</a></span></li><li><span><a href=\"#Apply-different-NN-architectures\" data-toc-modified-id=\"Apply-different-NN-architectures-8.6\"><span class=\"toc-item-num\">8.6&nbsp;&nbsp;</span>Apply different NN architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convolutional-NN-(CNN)\" data-toc-modified-id=\"Convolutional-NN-(CNN)-8.6.1\"><span class=\"toc-item-num\">8.6.1&nbsp;&nbsp;</span>Convolutional NN (CNN)</a></span></li><li><span><a href=\"#Recurrent-NN-(RNN)\" data-toc-modified-id=\"Recurrent-NN-(RNN)-8.6.2\"><span class=\"toc-item-num\">8.6.2&nbsp;&nbsp;</span>Recurrent NN (RNN)</a></span></li><li><span><a href=\"#Long-Short-Term-Memory-Networks-(LSTM)\" data-toc-modified-id=\"Long-Short-Term-Memory-Networks-(LSTM)-8.6.3\"><span class=\"toc-item-num\">8.6.3&nbsp;&nbsp;</span>Long Short-Term Memory Networks (LSTM)</a></span></li><li><span><a href=\"#Kernalized-NN\" data-toc-modified-id=\"Kernalized-NN-8.6.4\"><span class=\"toc-item-num\">8.6.4&nbsp;&nbsp;</span>Kernalized NN</a></span></li><li><span><a href=\"#Comparison-of-the-results\" data-toc-modified-id=\"Comparison-of-the-results-8.6.5\"><span class=\"toc-item-num\">8.6.5&nbsp;&nbsp;</span>Comparison of the results</a></span></li></ul></li></ul></li><li><span><a href=\"#Compare-SVM-and-NN-models-in-terms-of-predictive-performance-and-computation-time\" data-toc-modified-id=\"Compare-SVM-and-NN-models-in-terms-of-predictive-performance-and-computation-time-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Compare SVM and NN models in terms of predictive performance and computation time</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "* Load and train NN Grid Seach params\n",
    "* properly save best params\n",
    "* rearrange methods\n",
    "* measure time when using GridSearch\n",
    "* create Matrix Graph from the produced scores\n",
    "* free memory when creating objects in Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "from dask_ml.model_selection import GridSearchCV as DaskGridSearchCV\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import time\n",
    "\n",
    "import shap\n",
    "import lime\n",
    "\n",
    "import joblib\n",
    "\n",
    "import math\n",
    "\n",
    "from create_nn import create_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#print(\"Num GPUs Available:\", len([x for x in device_lib.list_local_devices() if x.device_type == 'GPU']))\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPU found.\")\n",
    "else:\n",
    "    print(f\"GPUs found: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"Device: {gpu.name}\")\n",
    "        print(gpu.device_type)\n",
    "        details = tf.config.experimental.get_memory_info(gpu.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = [1, 2, 6, 24] # time bins we want to predict the demand for\n",
    "resolution = ['h3_res_4', 'h3_res_6', 'h3_res_8'] # spatial resolution we want to predict the demand for\n",
    "\n",
    "prediction_data={}\n",
    "for period in time_periods:\n",
    "    res_data={}\n",
    "    for res in resolution:\n",
    "        res_data[res]=pd.read_csv(f'../data/{period}hours_{res}.csv', \n",
    "                                  parse_dates=['trip_start_timestamp'],\n",
    "                                  #index_col=\"trip_start_timestamp\"\n",
    "                                 )\n",
    "    prediction_data[period]=res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>h3_res_4</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>number_of_trips</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>lagged_1h</th>\n",
       "      <th>lagged_1day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>8426645ffffffff</td>\n",
       "      <td>-20.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>842664dffffffff</td>\n",
       "      <td>-20.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>8427593ffffffff</td>\n",
       "      <td>-20.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>8426645ffffffff</td>\n",
       "      <td>-18.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269797</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>842664dffffffff</td>\n",
       "      <td>-19.374470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269797</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_start_timestamp         h3_res_4  temperature  precipitation  \\\n",
       "0  2018-01-01 00:00:00  8426645ffffffff   -20.555556            0.0   \n",
       "1  2018-01-01 00:00:00  842664dffffffff   -20.555556            0.0   \n",
       "2  2018-01-01 00:00:00  8427593ffffffff   -20.555556            0.0   \n",
       "3  2018-01-01 01:00:00  8426645ffffffff   -18.333333            0.0   \n",
       "4  2018-01-01 01:00:00  842664dffffffff   -19.374470            0.0   \n",
       "\n",
       "   number_of_trips  weekday  month  hour  hour_sin  hour_cos   weekday_sin  \\\n",
       "0                2      1.0    1.0   0.0  0.000000  1.000000 -2.449294e-16   \n",
       "1             2321      1.0    1.0   0.0  0.000000  1.000000 -2.449294e-16   \n",
       "2               35      1.0    1.0   0.0  0.000000  1.000000 -2.449294e-16   \n",
       "3                2      1.0    1.0   1.0  0.269797  0.962917 -2.449294e-16   \n",
       "4             4192      1.0    1.0   1.0  0.269797  0.962917 -2.449294e-16   \n",
       "\n",
       "   weekday_cos  lagged_1h  lagged_1day  \n",
       "0          1.0        NaN          NaN  \n",
       "1          1.0        NaN          NaN  \n",
       "2          1.0        NaN          NaN  \n",
       "3          1.0        2.0          NaN  \n",
       "4          1.0     2321.0          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data.get(1).get('h3_res_4').head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Method that prepares the data for training (split the data/)\n",
    "    param X: feature data to be prepared\n",
    "    param Y: target data to be prepared\n",
    "    param train_index: index that defines the split for trainig data\n",
    "    param val_index: index that defines the split for target data\n",
    "    returns X_train, Y_train, X_val, Y_val: prepared training & validation data\n",
    "    '''\n",
    "    Scaler=StandardScaler()\n",
    "    \n",
    "    X_train = Scaler.fit_transform(X_train)\n",
    "    Y_train = Scaler.fit_transform(Y_train)\n",
    "    \n",
    "    X_test = Scaler.fit_transform(X_test)\n",
    "    Y_test = Scaler.fit_transform(Y_test)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def train_lsvr(X_train, Y_train, X_val, Y_val, model, params):\n",
    "    '''\n",
    "    This method compiles and trains a SVM with the given data and parameters\n",
    "    param X_train: Training data-set\n",
    "    param Y_train: Target variable for training\n",
    "    param X_val:   Test data-set\n",
    "    param y_val:   Target variable for validation\n",
    "    param model:   SVM to be trained\n",
    "    param params:  Parameters to train the SVM\n",
    "    returns:       Nothing    \n",
    "    '''\n",
    "    model.set_params(\n",
    "              epsilon = params.get('regressor__model__epsilon'),\n",
    "              C = params.get('regressor__model__C'),\n",
    "              max_iter = 5000\n",
    "    )\n",
    "    model.fit(X_train, \n",
    "              Y_train.reshape(len(Y_train))\n",
    "             )\n",
    "    Y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(Y_val, Y_pred)\n",
    "    MAE = mean_absolute_error(Y_val, Y_pred)\n",
    "    print(f\"R-squared {r2}\")\n",
    "    print(f\"Mean Squared Error {MAE}\")\n",
    "    \n",
    "    \n",
    "def train_ksvr(X_train, Y_train, X_val, Y_val, model, params):\n",
    "    '''\n",
    "    This method compiles and trains a SVM with the given data and parameters\n",
    "    param X_train: Training data-set\n",
    "    param Y_train: Target variable for training\n",
    "    param X_val:   Test data-set\n",
    "    param y_val:   Target variable for validation\n",
    "    param model:   SVM to be trained\n",
    "    param params:  Parameters to train the SVM\n",
    "    returns:       Nothing    \n",
    "    '''\n",
    "    print(params)\n",
    "    model.set_params(\n",
    "              epsilon = params.get('regressor__model__epsilon'),\n",
    "              C = params.get('regressor__model__C'),\n",
    "              kernel = params.get('regressor__model__kernel'),\n",
    "              gamma = params.get('regressor__model__gamma'),\n",
    "              coef0 = params.get('regressor__model__coef0')\n",
    "    )\n",
    "    model.fit(X_train, \n",
    "              Y_train.reshape(len(Y_train))\n",
    "             )\n",
    "    Y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(Y_val, Y_pred)\n",
    "    MAE = mean_absolute_error(Y_val, Y_pred)\n",
    "    print(f\"R-squared {r2}\")\n",
    "    print(f\"Mean Squared Error {MAE}\")\n",
    "\n",
    "\n",
    "def create_date_list(delta):\n",
    "    '''\n",
    "    This method creates a list of dates (2018-2019) \n",
    "    depending on the delta\n",
    "    params delta: determines break between dates\n",
    "    returns:      list of dates \n",
    "    '''\n",
    "    # create a startdate\n",
    "    start = pd.to_datetime(\"2018-01-01\", format=\"%Y-%m-%d\")\n",
    "    # create the enddate\n",
    "    #end = pd.to_datetime(\"2018-12-31\", format=\"%Y-%m-%d\")\n",
    "    end = pd.to_datetime(\"2018-01-20\", format=\"%Y-%m-%d\")\n",
    "    # create timedelta to increase days\n",
    "    next_date = timedelta(days=delta)\n",
    "    list_dates=[]\n",
    "    \n",
    "    while start <= end:\n",
    "        \n",
    "        # add date to list\n",
    "        list_dates.append(start)\n",
    "        # increase date by one day\n",
    "        start = start + next_date\n",
    "    list_dates.append(end)\n",
    "    \n",
    "    return list_dates\n",
    "\n",
    "\n",
    "def create_batch_split(X,Y, date_list, arr):\n",
    "    '''\n",
    "    '''\n",
    "    X_train = X.copy()\n",
    "    Y_train = Y.copy()\n",
    "    X_test = pd.DataFrame()\n",
    "    Y_test = pd.DataFrame()\n",
    "    # Sort the arr to be able to delete entries with the index\n",
    "    arr = sorted(arr, reverse=True)\n",
    "    for element in arr:\n",
    "        # extract batch\n",
    "        batch_x = X.loc[(X.index < date_list[element]) & (X.index >= date_list[element] - timedelta(days=7))]\n",
    "        batch_y = Y.loc[(Y.index < date_list[element]) & (Y.index >= date_list[element] - timedelta(days=7))]\n",
    "        # add to the test sets\n",
    "        X_test = pd.concat([batch_x, X_test])\n",
    "        Y_test = pd.concat([batch_y, Y_test])\n",
    "        # delete from the training data set\n",
    "        X_train.drop(index=batch_x.index, inplace=True)\n",
    "        Y_train.drop(index=batch_y.index, inplace=True)\n",
    "        # Delete the elements from the date_list that have been already used for the test set\n",
    "        del date_list[element]\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def get_columns(df, subset):\n",
    "    features = list(df.columns)\n",
    "    if subset == \"cos\":\n",
    "        features.remove(\"weekday\")\n",
    "        features.remove(\"month\")\n",
    "        features.remove(\"hour\")\n",
    "        features.remove(\"number_of_trips\")\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Train split Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_k_fold_validation(k, X, Y, model, train_model, params):\n",
    "    '''\n",
    "    Method that trains and validate the model using k-fold validation\n",
    "    However, this method can disrupt the temporal patterns and data leakage occurs \n",
    "    due to the lagged time features\n",
    "    param k:      Number of folds (iterations)\n",
    "    param x:      Feature data\n",
    "    param y:      Target data\n",
    "    param model:  Model to be trained ()\n",
    "    returns:      Nothing\n",
    "    '''\n",
    "    # initialize the folds\n",
    "    k_fold = KFold(n_splits= k, random_state=47, shuffle=True)\n",
    "    # iteratre through all folds\n",
    "    for train_index, val_index in k_fold.split(X,Y):\n",
    "        # normalize data\n",
    "        X_train, Y_train, X_val, Y_val = normalize_data(\n",
    "            X.iloc[train_index],\n",
    "            Y.iloc[train_index].values.reshape(-1,1), \n",
    "            X.iloc[val_index], \n",
    "            Y.iloc[val_index].values.reshape(-1,1)\n",
    "        )\n",
    "        # train & validate the model\n",
    "        train_model(X_train=X_train, Y_train= Y_train, X_val=X_val, Y_val=Y_val,  model=model, params=params)\n",
    "\n",
    "        \n",
    "def batch_split_cross_validation(k, time_bin, X, Y, model, train_model, params):\n",
    "    '''\n",
    "    This method split the entire dataset into batches. Direct Data Leakage is avoided by disrupting\n",
    "    the chain of the lagged time feature between test and training set. Batches are cut on week and day level \n",
    "    depending on the granularity of the time bins.\n",
    "    param X:              feature data \n",
    "    param Y:              target data\n",
    "    param k_folds:        number of folds for k-fold validation\n",
    "    param time_bin:       granularity of the time bins\n",
    "    returns index_dict:   contains indicies to split for cross validation\n",
    "    '''\n",
    "    # if 24 split batches by weeks\n",
    "    if time_bin == 24:\n",
    "        date_list = create_date_list(7)    \n",
    "    # else split by days\n",
    "    else:\n",
    "        date_list = create_date_list(1)\n",
    "    # number of batches that are included in the test set\n",
    "    size_test_split = len(date_list) // k\n",
    "    for fold in range(0, k):\n",
    "        print(fold)\n",
    "        # pick random choices for the test data batches\n",
    "        if fold==k-1:\n",
    "            arr = np.random.choice(range(1, len(date_list)), len(date_list)-1, replace=False)\n",
    "        else: \n",
    "            arr = np.random.choice(range(1, len(date_list)), size_test_split, replace=False)   \n",
    "        # create training and test set with the batches\n",
    "        X_train, Y_train, X_test, Y_test = create_batch_split(X,Y, date_list, arr)\n",
    "        # normalize the data\n",
    "        X_train, Y_train, X_test, Y_test = normalize_data(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            X_test,\n",
    "            Y_test\n",
    "        )\n",
    "        # train & validate the model\n",
    "        train_model(X_train=X_train, Y_train= Y_train, X_val=X_test, Y_val=Y_test,  model=model, params=params)\n",
    "\n",
    "def sorted_train_test_split(X, Y, test_size, model, train_model, params):\n",
    "    '''\n",
    "    '''\n",
    "    # sort the entries in ascending order\n",
    "    X.sort_index(inplace=True)\n",
    "    Y.sort_index(inplace=True)\n",
    "    # get split index\n",
    "    test_index = int(len(X)*(1-test_size))-1\n",
    "    # normalize data\n",
    "    X_train, Y_train, X_val, Y_val = normalize_data(\n",
    "        X.iloc[:test_index],\n",
    "        Y.iloc[:test_index].values.reshape(-1,1), \n",
    "        X.iloc[test_index:], \n",
    "        Y.iloc[test_index:].values.reshape(-1,1)\n",
    "    )\n",
    "    # train & validate the model\n",
    "    train_model(X_train=X_train, Y_train= Y_train, X_val=X_val, Y_val=Y_val,  model=model, params=params)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "# encode the hexagons in dummy variables\n",
    "\n",
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        df = prediction_data.get(period).get(res)\n",
    "\n",
    "        df[f'lagged_1day'].fillna(df['number_of_trips'].mean(), inplace= True)\n",
    "        if period!=24:\n",
    "            df[f'lagged_{period}h'].fillna(df['number_of_trips'].mean(), inplace= True)\n",
    "        \n",
    "        encoded_data = encoder.fit_transform(df[[res]])\n",
    "        encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([res]))\n",
    "\n",
    "        #df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        df = pd.concat([df, encoded_df], axis=1).drop(res, axis=1)\n",
    "        df.set_index(\"trip_start_timestamp\", inplace=True);\n",
    "        \n",
    "        prediction_data[period][res] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature_Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_linear = {\n",
    "    'regressor__model__C': [0.1, 1, 10, 100, 150],\n",
    "    'regressor__model__epsilon': [0.01, 0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "param_grid_k = {\n",
    "    'regressor__model__C': [0.1, 1, 10, 100, 150],\n",
    "    'regressor__model__epsilon': [0.01, 0.1, 0.5, 1],\n",
    "    #'regressor__model__kernel': ['rbf','sigmoid', 'poly'],\n",
    "    'regressor__model__kernel': ['rbf', 'sigmoid'],\n",
    "    'regressor__model__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "    'regressor__model__coef0': [0, 0.1, 0.5, 1],  # Relevant for 'poly' and 'sigmoid' kernels\n",
    "    #'regressor__model__degree': [2, 3, 4]  # Only relevant for 'poly' kernel\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_sv(tss, scaler, model, params, name):\n",
    "    '''\n",
    "    param tss:     TimeSeriesSplitObject to perform gridsearch on a timeseries split\n",
    "    param scaler:  preferred scaler to rescale the data\n",
    "    param model:   model used in the GS\n",
    "    param params:  param gird for the GS\n",
    "    param name:    name to store the params with joblib\n",
    "    '''\n",
    "    for period in time_periods:\n",
    "        for res in resolution: \n",
    "            \n",
    "            print(f\"time period:{period}, resolution:{res}\")\n",
    "            df = prediction_data.get(period).get(res)\n",
    "            \n",
    "            columns= get_columns(df,'cos')\n",
    "            \n",
    "            # create pipline to scale the data\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', scaler),\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "            # create TransformedTargetRegressor to scale target variable\n",
    "            ttr = TransformedTargetRegressor(\n",
    "                regressor = pipeline,\n",
    "                transformer = scaler\n",
    "            )\n",
    "\n",
    "            # create dask grid search object (dask to enable parallel computing)\n",
    "            Dask_GS = DaskGridSearchCV(\n",
    "                estimator=ttr,\n",
    "                param_grid=params,\n",
    "                cv=tss,\n",
    "                scoring='r2',\n",
    "                n_jobs=-1 #use a available cores\n",
    "            )\n",
    "\n",
    "            # use Client() for enable parallel computing with dask\n",
    "            try:\n",
    "                with Client() as client:\n",
    "\n",
    "                    num_cores = client.ncores()\n",
    "                    print(f\"Number of cores: {num_cores}\")\n",
    "                    print(f\"Dashboard link: {client.dashboard_link}\")\n",
    "\n",
    "                    start_time = time.time() # time computation time for the gridsearch\n",
    "                    warnings.filterwarnings('ignore', message='Liblinear failed to converge, increase the number of iterations.')\n",
    "                    Dask_GS.fit(df[columns], df['number_of_trips']) # fit the grid search\n",
    "                    end_time = time.time()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Exception {e} occured, swtich to running only one job\")\n",
    "\n",
    "                Dask_GS.n_jobs=1\n",
    "\n",
    "                start_time = time.time() # time computation time for the gridsearch\n",
    "                warnings.filterwarnings('ignore', message='Liblinear failed to converge, increase the number of iterations.')\n",
    "                Dask_GS.fit(df[columns], df['number_of_trips']) # fit the grid search\n",
    "                end_time = time.time()\n",
    "\n",
    "            print(f\"GridSearch took: {(end_time-start_time)/60} minuts\")\n",
    "            joblib.dump(Dask_GS.best_params_, f'Models/{name}_{period}_{res}')\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=4)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time period:1, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:63385': 2, 'tcp://127.0.0.1:63386': 2, 'tcp://127.0.0.1:63399': 2, 'tcp://127.0.0.1:63400': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.13869111935297648 minuts\n",
      "time period:1, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:63460': 2, 'tcp://127.0.0.1:63461': 2, 'tcp://127.0.0.1:63466': 2, 'tcp://127.0.0.1:63469': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.4465000033378601 minuts\n",
      "time period:1, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:63513': 2, 'tcp://127.0.0.1:63518': 2, 'tcp://127.0.0.1:63527': 2, 'tcp://127.0.0.1:63528': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 6.700880571206411 minuts\n",
      "time period:2, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:63580': 2, 'tcp://127.0.0.1:63593': 2, 'tcp://127.0.0.1:63594': 2, 'tcp://127.0.0.1:63599': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.1312586506207784 minuts\n",
      "time period:2, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:63657': 2, 'tcp://127.0.0.1:63660': 2, 'tcp://127.0.0.1:63662': 2, 'tcp://127.0.0.1:63664': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.23698410193125408 minuts\n",
      "time period:2, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:63707': 2, 'tcp://127.0.0.1:63722': 2, 'tcp://127.0.0.1:63725': 2, 'tcp://127.0.0.1:63726': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 3.963459583123525 minuts\n",
      "time period:6, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:63779': 2, 'tcp://127.0.0.1:63786': 2, 'tcp://127.0.0.1:63787': 2, 'tcp://127.0.0.1:63792': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.09456448554992676 minuts\n",
      "time period:6, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:63852': 2, 'tcp://127.0.0.1:63855': 2, 'tcp://127.0.0.1:63856': 2, 'tcp://127.0.0.1:63860': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.13686476945877074 minuts\n",
      "time period:6, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:63916': 2, 'tcp://127.0.0.1:63919': 2, 'tcp://127.0.0.1:63920': 2, 'tcp://127.0.0.1:63922': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 1.6676704049110413 minuts\n",
      "time period:24, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:63964': 2, 'tcp://127.0.0.1:63979': 2, 'tcp://127.0.0.1:63980': 2, 'tcp://127.0.0.1:63985': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.11951696475346883 minuts\n",
      "time period:24, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:64043': 2, 'tcp://127.0.0.1:64044': 2, 'tcp://127.0.0.1:64049': 2, 'tcp://127.0.0.1:64050': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.10335323413213095 minuts\n",
      "time period:24, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:64102': 2, 'tcp://127.0.0.1:64113': 2, 'tcp://127.0.0.1:64116': 2, 'tcp://127.0.0.1:64119': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.5556763092676799 minuts\n"
     ]
    }
   ],
   "source": [
    "#SVR()\n",
    "grid_search_sv(tss, scaler, LinearSVR(), param_grid_linear, 'SVR/LSVR/params/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time period:1, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:57731': 2, 'tcp://127.0.0.1:57732': 2, 'tcp://127.0.0.1:57733': 2, 'tcp://127.0.0.1:57739': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2588\\1970611385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search_sv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SVR/KSVR/params/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2588\\1140630691.py\u001b[0m in \u001b[0;36mgrid_search_sv\u001b[1;34m(tss, scaler, model, params, name)\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# time computation time for the gridsearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Liblinear failed to converge, increase the number of iterations.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                     \u001b[0mDask_GS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_of_trips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fit the grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\dask_ml\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m   1271\u001b[0m             \u001b[0mresult_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m             \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1273\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1274\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36mbatches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5092\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5093\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5094\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5095\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5096\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   5064\u001b[0m         \"\"\"\n\u001b[0;32m   5065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5066\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5067\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5068\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5025\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5026\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5027\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5028\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_and_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search_sv(tss, scaler, SVR(), param_grid_k, 'SVR/KSVR/params/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models with different time/spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__model__C': 1, 'regressor__model__epsilon': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Load the best models and params from the gridsearch and safe them in a dictionary\n",
    "params_lsvr={}\n",
    "params_ksvr={}\n",
    "for period in time_periods:\n",
    "    dict_lsvr = {}\n",
    "    dict_ksvr = {}\n",
    "    for res in resolution:\n",
    "        dict_lsvr[res] = joblib.load(f'Models/SVR/LSVR/params/lsvr_{period}_{res}')\n",
    "        dict_ksvr[res] = joblib.load(f'Models/SVR/KSVR/params/ksvr_{period}_{res}')\n",
    "    params_lsvr[period] = dict_lsvr\n",
    "    params_ksvr[period] = dict_ksvr\n",
    "\n",
    "print(params_lsvr.get(1).get('h3_res_4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Split k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Window Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start End Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "timeperiod: 1, resolution: h3_res_4\n",
      "R-squared 0.9373949859979163\n",
      "Mean Squared Error 0.13509675319123457\n",
      "\n",
      "timeperiod: 1, resolution: h3_res_6\n",
      "R-squared 0.9502339252544667\n",
      "Mean Squared Error 0.07906144136634256\n",
      "\n",
      "timeperiod: 1, resolution: h3_res_8\n",
      "R-squared 0.9363524462925581\n",
      "Mean Squared Error 0.11818743937339503\n",
      "\n",
      "timeperiod: 2, resolution: h3_res_4\n",
      "R-squared 0.9046087491066409\n",
      "Mean Squared Error 0.18153173925581612\n",
      "\n",
      "timeperiod: 2, resolution: h3_res_6\n",
      "R-squared 0.9143114507942116\n",
      "Mean Squared Error 0.08589017500442439\n",
      "\n",
      "timeperiod: 2, resolution: h3_res_8\n",
      "R-squared 0.8911982236941391\n",
      "Mean Squared Error 0.12336170605408628\n",
      "\n",
      "timeperiod: 6, resolution: h3_res_4\n",
      "R-squared 0.715897955307262\n",
      "Mean Squared Error 0.45929435978002664\n",
      "\n",
      "timeperiod: 6, resolution: h3_res_6\n",
      "R-squared 0.8456348732368068\n",
      "Mean Squared Error 0.1265012377397179\n",
      "\n",
      "timeperiod: 6, resolution: h3_res_8\n",
      "R-squared 0.8139644189886883\n",
      "Mean Squared Error 0.14977924581039145\n",
      "\n",
      "timeperiod: 24, resolution: h3_res_4\n",
      "R-squared 0.7855158185220934\n",
      "Mean Squared Error 0.22955514044871844\n",
      "\n",
      "timeperiod: 24, resolution: h3_res_6\n",
      "R-squared 0.7941571614150893\n",
      "Mean Squared Error 0.10774225604247555\n",
      "\n",
      "timeperiod: 24, resolution: h3_res_8\n",
      "R-squared 0.7503047746855773\n",
      "Mean Squared Error 0.13048165514112292\n"
     ]
    }
   ],
   "source": [
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        print(f'\\ntimeperiod: {period}, resolution: {res}')\n",
    "        \n",
    "        df = prediction_data.get(period).get(res)\n",
    "        columns = get_columns(df, \"cos\")\n",
    "        model = LinearSVR()\n",
    "        params= params_lsvr.get(period).get(res)\n",
    "        \n",
    "        sorted_train_test_split(df[columns], df[['number_of_trips']], 0.15, model, train_lsvr, params=params)\n",
    "        \n",
    "        joblib.dump(model, f'Models/SVR/LSVR/models/lsvr_{period}_{res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "timeperiod: 1, resolution: h3_res_4\n",
      "{'regressor__model__C': 1, 'regressor__model__epsilon': 0.01}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5940\\3473104395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mparams_ksvr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msorted_train_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_of_trips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ksvr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'Models/SVR/LSVR/models/ksvr_{period}_{res}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5940\\3270986540.py\u001b[0m in \u001b[0;36msorted_train_test_split\u001b[1;34m(X, Y, test_size, model, train_model, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# train & validate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5940\\616509197.py\u001b[0m in \u001b[0;36mtrain_ksvr\u001b[1;34m(X_train, Y_train, X_val, Y_val, model, params)\u001b[0m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[0;32m     97\u001b[0m     model.fit(X_train, \n\u001b[1;32m---> 98\u001b[1;33m               \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m              )\n\u001b[0;32m    100\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\_libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        print(f'\\ntimeperiod: {period}, resolution: {res}')\n",
    "        \n",
    "        df = prediction_data.get(period).get(res)\n",
    "        columns = get_columns(df, \"cos\")\n",
    "        model = SVR()\n",
    "        params= params_ksvr.get(period).get(res)\n",
    "        \n",
    "        sorted_train_test_split(df[columns], df[['number_of_trips']], 0.15, model, train_ksvr, params=params)\n",
    "        \n",
    "        joblib.dump(model, f'Models/SVR/LSVR/models/ksvr_{period}_{res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compare the results of the different time/spaitla bin combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyize the models with XAI methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_train_test_split(X, Y, test_size):\n",
    "    '''\n",
    "    '''\n",
    "    # sort the entries in ascending order\n",
    "    X.sort_index(inplace=True)\n",
    "    Y.sort_index(inplace=True)\n",
    "    # get split index\n",
    "    test_index = int(len(X)*(1-test_size))-1\n",
    "    # normalize data\n",
    "    X_train, Y_train, X_val, Y_val = normalize_data(\n",
    "        X.iloc[:test_index],\n",
    "        Y.iloc[:test_index].values.reshape(-1,1), \n",
    "        X.iloc[test_index:], \n",
    "        Y.iloc[test_index:].values.reshape(-1,1)\n",
    "    )\n",
    "    # train & validate the model\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(\n",
    "    input_size, \n",
    "    act_function, \n",
    "    decrease_func, \n",
    "    factor, \n",
    "    first_layer_factor,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    metrics,\n",
    "    dropout_rate,\n",
    "    learning_rate\n",
    "):\n",
    "    nn = Sequential()\n",
    "    neurons = int(input_size * first_layer_factor)\n",
    "    nn.add(Dense(neurons, input_shape=(input_size,), activation=act_function))\n",
    "    counter = 1\n",
    "    while True:\n",
    "        if decrease_func == \"exp\":\n",
    "            neurons = exp_dec_func(neurons, counter, factor)\n",
    "        elif decrease_func == \"linear\":\n",
    "            neurons = linear_dec_func(neurons, counter, factor)\n",
    "        if neurons <= 1:\n",
    "            break\n",
    "        else:\n",
    "            nn.add(Dense(neurons, activation=act_function))\n",
    "            nn.add(Dropout(dropout_rate))\n",
    "            counter += 1\n",
    "    nn.add(Dense(1))\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer_instance = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer_instance = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSPROP':\n",
    "        optimizer_instance = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        print(\"invalid optimizer\")\n",
    "        \n",
    "    nn.compile(\n",
    "        optimizer=optimizer_instance,\n",
    "        loss=loss,\n",
    "        metrics=[metrics],\n",
    "    )\n",
    "    return nn\n",
    "\n",
    "def linear_dec_func(neurons, counter, factor):\n",
    "    return int((1 - factor * counter) * neurons)\n",
    "\n",
    "def exp_dec_func(neurons, counter, factor=0.25):\n",
    "    return int(math.exp(-counter * factor) * neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_train, Y_train, X_val, Y_val, model, params):\n",
    "    '''\n",
    "    This method compiles and trains a neural network with the given data and parameters\n",
    "    param X_train: Training data-set\n",
    "    param Y_train: Target variable for training\n",
    "    param X_val:   Test data-set\n",
    "    param y_val:   Target variable for validation\n",
    "    param model:   NN to be trained\n",
    "    param params:  Parameters to compile and fit the NN\n",
    "    returns:       Nothing     \n",
    "    '''\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        batch_size=params.get(\"batch_size\"),\n",
    "        epochs=params.get(\"epochs\"),\n",
    "        verbose=0,\n",
    "    )\n",
    "    Y_pred=model.predict(X_val)\n",
    "    r2 = r2_score(Y_val, Y_pred)\n",
    "    MAE = mean_absolute_error(Y_val, Y_pred)\n",
    "    print(f\"R-squared {r2}\")\n",
    "    print(f\"Mean Absolut Error {MAE}\\n\")\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_nn(param_grid, test_size):\n",
    "    \n",
    "    for period in time_periods:\n",
    "        for res in resolution: \n",
    "            \n",
    "            best_score = 1 \n",
    "            best_params = None\n",
    "\n",
    "            print(f\"time period:{period}, resolution:{res}\")\n",
    "            df = prediction_data.get(period).get(res)\n",
    "\n",
    "            columns= get_columns(df,'cos')\n",
    "            \n",
    "            X_train, Y_train, X_val, Y_val = sorted_train_test_split(df[columns], df['number_of_trips'], test_size)\n",
    "            \n",
    "            grid_object = ParameterGrid(param_grid)\n",
    "            print(f\"Number of parameter combinations: {len(grid_object)}\")\n",
    "            \n",
    "            results=[]\n",
    "            for params in grid_object:\n",
    "                results.append(create_train(params, len(columns), X_train, Y_train, X_val, Y_val))\n",
    "            dask.compute(results)\n",
    "            print(results)\n",
    "            joblib.dump(best_params, f'Models/FNN/params/nn_{period}_{res}')\n",
    "            break\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def create_train(params, columns, X_train, Y_train, X_val, Y_val):\n",
    "    print(params)\n",
    "    nn = create_nn(\n",
    "        input_size= columns, \n",
    "        act_function = params['act_function'], \n",
    "        decrease_func = params['decrease_func'], \n",
    "        factor = params['factor'], \n",
    "        first_layer_factor = params['first_layer_factor'],\n",
    "        optimizer = params['optimizer'],\n",
    "        loss = params['loss'],\n",
    "        metrics = params['metrics'],\n",
    "        dropout_rate = params['dropout_rate'],\n",
    "        learning_rate = params['learning_rate']\n",
    "            )\n",
    "    params_train={\n",
    "        'epochs' : 300,\n",
    "        'batch_size' : params['batch_size']\n",
    "        }\n",
    "    score = train_nn(X_train=X_train, Y_train= Y_train, X_val=X_val, Y_val=Y_val,  model=nn, params=params)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nn = {\n",
    "    'learning_rate': [0.001, 0.005, 0.01],\n",
    "    'batch_size': [25, 50, 75],\n",
    "    'optimizer': ['SGD', 'Adam', 'RMSPROP'],\n",
    "    #'regressor__model__act_function': ['relu', 'tanh', 'elu'],\n",
    "    'act_function': ['relu'],\n",
    "    'dropout_rate': [0.2, 0.5],\n",
    "    'loss': ['mse'],\n",
    "    'metrics': ['mae'],\n",
    "    #'regressor__model__first_layer_factor': [0.8, 1, 1.2],\n",
    "    'first_layer_factor': [1],\n",
    "    'factor': [1],\n",
    "    'decrease_func': [\"exp\", \"linear\"],\n",
    "    'epochs': [200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time period:1, resolution:h3_res_4\n",
      "Number of parameter combinations: 108\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.964889545707907\n",
      "Mean Absolut Error 0.0994646138043035\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.8776523629707949\n",
      "Mean Absolut Error 0.2743928591910229\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9612203009652409\n",
      "Mean Absolut Error 0.133636372580003\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9657258110436059\n",
      "Mean Absolut Error 0.09812474881500263\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9528579120441353\n",
      "Mean Absolut Error 0.11881001543219775\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9484116080523397\n",
      "Mean Absolut Error 0.15535723661245254\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.822350639769606\n",
      "Mean Absolut Error 0.32204401566563984\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9743958990268944\n",
      "Mean Absolut Error 0.11049565392581293\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9455796599654209\n",
      "Mean Absolut Error 0.15278606782990564\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.944605923136449\n",
      "Mean Absolut Error 0.14446379336057733\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.8305684553795531\n",
      "Mean Absolut Error 0.3181388253760173\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.5866159960526907\n",
      "Mean Absolut Error 0.5042733535604426\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9755350812245805\n",
      "Mean Absolut Error 0.0900259535619694\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9644996612011699\n",
      "Mean Absolut Error 0.11491492278276225\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.8413407762931554\n",
      "Mean Absolut Error 0.30041827704556084\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9523174799379905\n",
      "Mean Absolut Error 0.11942780902904898\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.8327418289710571\n",
      "Mean Absolut Error 0.32615604348026966\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.7391771166436578\n",
      "Mean Absolut Error 0.39923573549692415\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9569627327144461\n",
      "Mean Absolut Error 0.12801804605494665\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9387596377395759\n",
      "Mean Absolut Error 0.13747476241821988\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9708956937302337\n",
      "Mean Absolut Error 0.09456961878498062\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9670177384213916\n",
      "Mean Absolut Error 0.12105601810326151\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared 0.7997461789618301\n",
      "Mean Absolut Error 0.3420325457321635\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9450338991671124\n",
      "Mean Absolut Error 0.13507125485338348\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.7878928661139647\n",
      "Mean Absolut Error 0.340469057060893\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.8519276606535089\n",
      "Mean Absolut Error 0.2478887608210116\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9527752802325461\n",
      "Mean Absolut Error 0.13561397239058437\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9731939985880215\n",
      "Mean Absolut Error 0.08238569416707141\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.7433078272590148\n",
      "Mean Absolut Error 0.38723462940930836\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.972554346696638\n",
      "Mean Absolut Error 0.09859663611823416\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9534639118743774\n",
      "Mean Absolut Error 0.10787306286750421\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9548429916395337\n",
      "Mean Absolut Error 0.1179331296940579\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.8197308978951097\n",
      "Mean Absolut Error 0.3266433914905588\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.4407074631962733\n",
      "Mean Absolut Error 0.5521458811691697\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.805237707004516\n",
      "Mean Absolut Error 0.3304615059405392\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.8505058918760555\n",
      "Mean Absolut Error 0.2502947652094658\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.8756451388801104\n",
      "Mean Absolut Error 0.2693434992599636\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.6386183032121904\n",
      "Mean Absolut Error 0.411110126245107\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9734916019945326\n",
      "Mean Absolut Error 0.08826504886510336\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9588013150229264\n",
      "Mean Absolut Error 0.11465292775382656\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9712848600861277\n",
      "Mean Absolut Error 0.11215704813979907\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9384071617650075\n",
      "Mean Absolut Error 0.1850996494157354\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9730683931545334\n",
      "Mean Absolut Error 0.09244513358152395\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.8735802215576044\n",
      "Mean Absolut Error 0.27459856960479506\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9731842755306789\n",
      "Mean Absolut Error 0.0900850434965333\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9727448746283973\n",
      "Mean Absolut Error 0.08998238795197434\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9458403708137695\n",
      "Mean Absolut Error 0.14654240916552005\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9424283583259022\n",
      "Mean Absolut Error 0.14749828235767956\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.884274545000558\n",
      "Mean Absolut Error 0.2721086794269176\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.957038787222689\n",
      "Mean Absolut Error 0.10565353897325425\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9194814128343309\n",
      "Mean Absolut Error 0.19494408178459793\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared 0.9601701756109917\n",
      "Mean Absolut Error 0.1020472917223781\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9729273710775168\n",
      "Mean Absolut Error 0.0943683044432168\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.6830542671805444\n",
      "Mean Absolut Error 0.41831993034326626\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9469632306962016\n",
      "Mean Absolut Error 0.13275247626086784\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.896454213561015\n",
      "Mean Absolut Error 0.25107136266221275\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9605546584728851\n",
      "Mean Absolut Error 0.13090605784706064\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9686205506551332\n",
      "Mean Absolut Error 0.0939290376194239\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9456978397381917\n",
      "Mean Absolut Error 0.15681872756341747\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9570933876875262\n",
      "Mean Absolut Error 0.11218913361438158\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9684764856296179\n",
      "Mean Absolut Error 0.10824173028866041\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.976021146698401\n",
      "Mean Absolut Error 0.08602163979417325\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9708834531738157\n",
      "Mean Absolut Error 0.09368401606062551\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.7824999204348932\n",
      "Mean Absolut Error 0.35655340891070786\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9456140111966537\n",
      "Mean Absolut Error 0.12397052210211974\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9574733440254123\n",
      "Mean Absolut Error 0.11267358741004085\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9670222196725503\n",
      "Mean Absolut Error 0.09621067351243505\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.8480861190537636\n",
      "Mean Absolut Error 0.2657730828749077\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9678090600992604\n",
      "Mean Absolut Error 0.11329431712970756\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9532900108910495\n",
      "Mean Absolut Error 0.11512109158241243\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.8457375122652768\n",
      "Mean Absolut Error 0.30479825084084294\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.811831806372894\n",
      "Mean Absolut Error 0.35461758404547883\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9732787875030816\n",
      "Mean Absolut Error 0.08029829231996302\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9730012142044483\n",
      "Mean Absolut Error 0.08499158580381182\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9701458801993499\n",
      "Mean Absolut Error 0.11538373731612464\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.7839809341584865\n",
      "Mean Absolut Error 0.3804810115769231\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9514979335242915\n",
      "Mean Absolut Error 0.11736879943976429\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9612501205679577\n",
      "Mean Absolut Error 0.10639604972293351\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9617917677388419\n",
      "Mean Absolut Error 0.10886076345228148\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9728542271328944\n",
      "Mean Absolut Error 0.09275924636595086\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared 0.960375263897206\n",
      "Mean Absolut Error 0.10783712759384732\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9590869201089866\n",
      "Mean Absolut Error 0.1048851435101797\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.5536089581786087\n",
      "Mean Absolut Error 0.4889705862189061\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.974705908519725\n",
      "Mean Absolut Error 0.08934365967372575\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.971240496961829\n",
      "Mean Absolut Error 0.1029286290869584\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9499569957981068\n",
      "Mean Absolut Error 0.13006282344347708\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9756656807593257\n",
      "Mean Absolut Error 0.08593179281231424\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9722930070558795\n",
      "Mean Absolut Error 0.10398258515703233\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9509693959619272\n",
      "Mean Absolut Error 0.13573372488928614\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.8598854565629526\n",
      "Mean Absolut Error 0.2580109902284096\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9679395596027713\n",
      "Mean Absolut Error 0.09149336634443789\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.8572603989259853\n",
      "Mean Absolut Error 0.2800368634325533\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.46369843696412516\n",
      "Mean Absolut Error 0.5434310404413863\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9481089672032526\n",
      "Mean Absolut Error 0.12477437832433538\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9411402273111731\n",
      "Mean Absolut Error 0.1524952003303663\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'RMSPROP'}\n",
      "R-squared 0.9734828425503382\n",
      "Mean Absolut Error 0.08902349393837117\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9221805492123181\n",
      "Mean Absolut Error 0.18888219922857769\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'linear', 'dropout_rate': 0.5, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'SGD'}\n",
      "R-squared 0.9611706669591257\n",
      "Mean Absolut Error 0.09891665939576756\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 50, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.005, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9223716863130655\n",
      "Mean Absolut Error 0.16462578287314097\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 75, 'decrease_func': 'exp', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.001, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.9692404795179432\n",
      "Mean Absolut Error 0.11646666347241007\n",
      "\n",
      "{'act_function': 'relu', 'batch_size': 25, 'decrease_func': 'linear', 'dropout_rate': 0.2, 'epochs': 200, 'factor': 1, 'first_layer_factor': 1, 'learning_rate': 0.01, 'loss': 'mse', 'metrics': 'mae', 'optimizer': 'Adam'}\n",
      "R-squared 0.7602042913048137\n",
      "Mean Absolut Error 0.38117582335028194\n",
      "\n",
      "R-squared 0.9336003522491899\n",
      "Mean Absolut Error 0.1772225218746331\n",
      "\n",
      "R-squared 0.8515362380373072\n",
      "Mean Absolut Error 0.25277547323038346\n",
      "\n",
      "R-squared 0.9729726121206392\n",
      "Mean Absolut Error 0.10193304876207233\n",
      "\n",
      "R-squared 0.8479182318123619\n",
      "Mean Absolut Error 0.2959013204695445\n",
      "\n",
      "R-squared 0.7650682948039151\n",
      "Mean Absolut Error 0.35353466509278564\n",
      "\n",
      "R-squared 0.9555617797741879\n",
      "Mean Absolut Error 0.13790377963707853\n",
      "\n",
      "R-squared 0.9637904955465733\n",
      "Mean Absolut Error 0.12746332093854174\n",
      "\n",
      "[Delayed('create_train-68feec16-4c22-49ca-b6c9-4fa6df95bbc3'), Delayed('create_train-926d6ac2-3391-42b6-8b88-369cc5c98819'), Delayed('create_train-30f39638-7d57-4fbe-baaa-980d03bd534f'), Delayed('create_train-2f377157-63b4-4123-8535-dde132a3e167'), Delayed('create_train-ef682437-e9aa-4e23-9122-5da7954adb21'), Delayed('create_train-75e119dc-ab59-4aa7-aec2-7360b6e734dc'), Delayed('create_train-ed16ec9c-dbdd-490d-af91-3d3f4acc371b'), Delayed('create_train-b0ab30fb-5baf-4368-aa60-62f1bebe62c2'), Delayed('create_train-0719eacc-ac9e-41ae-ad66-f52eab9eaeeb'), Delayed('create_train-ebf28fca-9b01-4724-ae9a-670f56465fe6'), Delayed('create_train-01422ec9-86a0-4548-b752-e7ccad2b5319'), Delayed('create_train-cc5fc0d8-ca93-4c01-9c95-a161bb84cc40'), Delayed('create_train-42a0030e-32fd-430d-a356-5fc5b02ef300'), Delayed('create_train-a91ef23b-9421-472c-87da-8b386491d99e'), Delayed('create_train-10deee21-ebe6-4910-bd8e-825727619111'), Delayed('create_train-177b4308-7211-4b65-bfec-8081e382b57e'), Delayed('create_train-e53e7ccd-f919-4638-97e5-4af9af2b3ce0'), Delayed('create_train-1b23e5b4-5577-49ed-9b0a-edf4a01fe8c3'), Delayed('create_train-cfc51f22-7b83-4c11-a6bb-3b16ac1ffdb4'), Delayed('create_train-b42f2170-8507-42a3-8696-dea1f79a93c3'), Delayed('create_train-5eca4ac5-a66a-477c-98d1-7819c248fb0f'), Delayed('create_train-55e4b0eb-a629-4550-bf63-1fcacb828be3'), Delayed('create_train-bca97472-d3d3-4703-a1fc-f8e9f00d51fa'), Delayed('create_train-a8c877b6-448e-4124-8197-773d853f9c21'), Delayed('create_train-8994b3f8-6fc2-4725-a82e-0bc53c4e6375'), Delayed('create_train-fdce50e5-c318-4174-877c-d16ffddebe32'), Delayed('create_train-ab35b9a9-d89b-49e2-8e35-df3ec3fc1936'), Delayed('create_train-22a42b78-875b-4755-993d-9afaa0928434'), Delayed('create_train-5f223141-e816-45f5-be27-9d7dd02fee8c'), Delayed('create_train-3a1a0864-2464-4cbf-a743-d8d15e70cc35'), Delayed('create_train-a38c299d-2d9a-4d0a-b62d-abc4526b4296'), Delayed('create_train-be03fad1-dc30-4d60-9759-82e8df50684d'), Delayed('create_train-be3d1aef-d0eb-4e32-aee7-90d7fd1ba0a3'), Delayed('create_train-e3a5625f-6868-437d-9c01-ab12022077aa'), Delayed('create_train-da166803-93a3-49e2-be17-38b0feaff348'), Delayed('create_train-74669291-35dc-4a76-8c7c-76236159ac26'), Delayed('create_train-e7b7373e-4693-436e-9a63-bff85c6ca0eb'), Delayed('create_train-536f85b9-af38-4b4b-a967-c8eaa1131ce2'), Delayed('create_train-85bc61dd-c8ed-4d76-aa82-92c137f7069c'), Delayed('create_train-6c98edd3-d9b9-4402-87f2-1481f5196553'), Delayed('create_train-0c625f6a-0ccf-45dc-9144-c5fef7248071'), Delayed('create_train-ad0b4703-8dc8-4474-95b9-f218fc4e45a2'), Delayed('create_train-112b8c89-6491-49c8-b137-57c7f88ba2ca'), Delayed('create_train-5ead1c49-742f-4ef3-a1cc-54e3af3368a8'), Delayed('create_train-e3b6d5c2-da99-4fca-97e6-54c315f6fc43'), Delayed('create_train-4b5a44cf-a3f9-443d-87d0-c881a71eb012'), Delayed('create_train-abf0ffbc-bb52-4e4a-a997-c40f4472e605'), Delayed('create_train-1fb3136c-657e-4995-9538-af04f55c7486'), Delayed('create_train-be77af01-f474-42fb-bb1a-3c430e44fd59'), Delayed('create_train-3bc633d9-e16a-4a41-896f-c23fb9882af0'), Delayed('create_train-6e6b2613-1a7b-4812-bd7c-cafd955f50d0'), Delayed('create_train-11b24f37-52ec-4358-9a88-291113a6cb63'), Delayed('create_train-5468a70d-8de3-4f6e-bf99-da2943839b64'), Delayed('create_train-7641e46b-d9ab-4e17-aaed-be208147f20c'), Delayed('create_train-2dbe03a1-0751-45d5-8362-75f8b5753437'), Delayed('create_train-b978fe2a-3801-478e-a939-48bea301b185'), Delayed('create_train-83e5d6d1-b973-4ee1-bbca-0b9fffa1e6d6'), Delayed('create_train-29b489c3-643b-4610-ac0e-f35bc10ca344'), Delayed('create_train-f98c07b1-cfe0-402a-b3c0-edea201c292f'), Delayed('create_train-4478359c-605b-4d32-9adc-8371ef3ac434'), Delayed('create_train-6f474a6c-a0df-41ae-b1cb-c2758a2ccd5e'), Delayed('create_train-5875ccd8-e978-4fff-931b-a4a223df4046'), Delayed('create_train-a8258ba3-e993-480a-8cc5-94ee1c191956'), Delayed('create_train-6c2e2fe2-31a8-47ee-b840-637bc61b6dbb'), Delayed('create_train-10744812-a1ad-4c9b-ac91-20a579d026f0'), Delayed('create_train-b54ba77f-5877-420f-8ec7-b60663017a6c'), Delayed('create_train-80042af5-3cfd-48eb-b4c5-5b02e2b1da81'), Delayed('create_train-7116851f-cf9d-430b-ad15-58906ec2913d'), Delayed('create_train-b7221666-87dd-4059-a54f-00f9eb67c8dd'), Delayed('create_train-4af65a49-3aba-4ced-b225-a22bfcafe3ff'), Delayed('create_train-0d617e3c-c7ab-4179-9a7e-60ac24a9a6f1'), Delayed('create_train-31d88443-9d7a-4345-a708-3739169f4b3e'), Delayed('create_train-d1b1ec5f-503e-42fd-a5d9-9b0f18a2cff6'), Delayed('create_train-fb8565bb-0597-4b69-9ad1-de2e1e5219d9'), Delayed('create_train-0c6d76cd-51d1-48a9-a8cf-2aea4336d57c'), Delayed('create_train-182ea93a-3c84-4ea8-8189-a23eb3d8954d'), Delayed('create_train-629e9b9c-d568-4dee-874d-63953a10861a'), Delayed('create_train-ef3f907e-8732-4926-9723-48bb4ee1288c'), Delayed('create_train-d29a6ee8-bef7-4330-b7cc-bf997209d226'), Delayed('create_train-97cfd99a-83ab-4387-b529-2c30dbe77bfe'), Delayed('create_train-27c9b547-c0d3-4c0f-9b4f-a5d8e350ae0c'), Delayed('create_train-79ca188a-408e-416d-ad66-1a69f52e61d4'), Delayed('create_train-06a83eb9-0cca-4881-9c4e-1cbdd9e1fa38'), Delayed('create_train-6ad2f34e-3f79-4065-b651-c7486d3f3a52'), Delayed('create_train-40d6d99b-4ed5-41dd-ad43-4a94c90da0c4'), Delayed('create_train-5d4140b1-5f2c-49d8-956e-dc1013fff1fa'), Delayed('create_train-9cac87c8-f490-4f8b-bf56-683f3b419e0d'), Delayed('create_train-49d0037a-17ac-4b3e-935e-c58e98d6928d'), Delayed('create_train-52901e14-c414-4f02-8868-d06b7e019d08'), Delayed('create_train-de50e951-5de9-41d5-97c3-d6cb5e5f6ff2'), Delayed('create_train-eb3293af-eab6-4944-a900-30b6bb3ef134'), Delayed('create_train-04323b2d-e396-4302-a999-51d881f0500c'), Delayed('create_train-75a1cdfb-10e4-4991-9110-973b44ff4c67'), Delayed('create_train-3e440eca-15f1-4ad9-b6d5-ca0d366a75b3'), Delayed('create_train-65c78017-dd5a-4e2f-b260-fbc9f9123d7a'), Delayed('create_train-9479c0a9-f66a-4d7f-885e-5f2ee143f38d'), Delayed('create_train-8a4df6ad-9e4b-4651-9777-8d7fbfa32e0b'), Delayed('create_train-a6ead4b5-6610-4c9d-86e9-a87035a8c671'), Delayed('create_train-cac4cb01-ca47-4c10-b07e-04db0ad833e8'), Delayed('create_train-f3c11618-60bb-4c82-af81-06d28b098d5f'), Delayed('create_train-4e2a7ad6-d3c3-421a-81d5-2be2d7701653'), Delayed('create_train-c6e7c6a5-d111-4c20-9065-8f6405dc72e2'), Delayed('create_train-cb6e0386-a1b7-454d-b77f-fcc51975a9de'), Delayed('create_train-ddaea67b-3950-4c1c-accb-09209f17b9ee'), Delayed('create_train-ad0f3359-075a-4b14-915e-7dc711fd0f47'), Delayed('create_train-a2f03185-9d93-46d8-ad1c-7b66d64a569d'), Delayed('create_train-2c0c3fd1-cadc-4ddc-a019-391734a41d42'), Delayed('create_train-3df81e53-21c2-4e96-ae2a-4b31b7d86445')]\n"
     ]
    }
   ],
   "source": [
    "grid_search_nn(param_grid_nn, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models with different time/spatial bins and different test/train spilt techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__model__act_function': 'relu', 'regressor__model__batch_size': 32, 'regressor__model__decrease_func': <function exp_dec_func at 0x0000021EAEB72678>, 'regressor__model__dropout_rate': 0.2, 'regressor__model__factor': 1, 'regressor__model__first_layer_factor': 0.8, 'regressor__model__input_size': 12, 'regressor__model__learning_rate': 0.1, 'regressor__model__loss': 'mse', 'regressor__model__metrics': ('mae',), 'regressor__model__optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "#Load the best models and params from the gridsearch and safe them in a dictionary\n",
    "params_fnn={}\n",
    "for period in time_periods:\n",
    "    dict_fnn = {}\n",
    "    for res in resolution:\n",
    "        dict_fnn[res] = joblib.load(f'Models/FNN/params/fnn_{period}_{res}')\n",
    "        break\n",
    "    params_fnn[period] = dict_fnn\n",
    "    break\n",
    "\n",
    "\n",
    "print(params_fnn.get(1).get('h3_res_4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Split k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Window Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start End Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "timeperiod: 1, resolution: h3_res_4\n",
      "Epoch 1/300\n",
      "1169/1169 [==============================] - 1s 721us/sample - loss: 0.3006 - mean_absolute_error: 0.3291\n",
      "Epoch 2/300\n",
      "1169/1169 [==============================] - 0s 186us/sample - loss: 0.1761 - mean_absolute_error: 0.2404\n",
      "Epoch 3/300\n",
      "1169/1169 [==============================] - 0s 136us/sample - loss: 0.1907 - mean_absolute_error: 0.2509\n",
      "Epoch 4/300\n",
      "1169/1169 [==============================] - 0s 129us/sample - loss: 0.2083 - mean_absolute_error: 0.2536\n",
      "Epoch 5/300\n",
      "1169/1169 [==============================] - 0s 122us/sample - loss: 0.2130 - mean_absolute_error: 0.2623\n",
      "Epoch 6/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2113 - mean_absolute_error: 0.2486\n",
      "Epoch 7/300\n",
      "1169/1169 [==============================] - 0s 135us/sample - loss: 0.1676 - mean_absolute_error: 0.2213\n",
      "Epoch 8/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.2227 - mean_absolute_error: 0.2587\n",
      "Epoch 9/300\n",
      "1169/1169 [==============================] - 0s 109us/sample - loss: 0.1891 - mean_absolute_error: 0.2477\n",
      "Epoch 10/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.2028 - mean_absolute_error: 0.2397\n",
      "Epoch 11/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.1872 - mean_absolute_error: 0.2419\n",
      "Epoch 12/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.1906 - mean_absolute_error: 0.2305\n",
      "Epoch 13/300\n",
      "1169/1169 [==============================] - 0s 136us/sample - loss: 0.1779 - mean_absolute_error: 0.2454\n",
      "Epoch 14/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2042 - mean_absolute_error: 0.2532\n",
      "Epoch 15/300\n",
      "1169/1169 [==============================] - 0s 139us/sample - loss: 0.2141 - mean_absolute_error: 0.2567\n",
      "Epoch 16/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.1693 - mean_absolute_error: 0.2230\n",
      "Epoch 17/300\n",
      "1169/1169 [==============================] - 0s 166us/sample - loss: 0.1923 - mean_absolute_error: 0.2356\n",
      "Epoch 18/300\n",
      "1169/1169 [==============================] - 0s 167us/sample - loss: 0.2308 - mean_absolute_error: 0.2804\n",
      "Epoch 19/300\n",
      "1169/1169 [==============================] - 0s 143us/sample - loss: 0.2273 - mean_absolute_error: 0.2850\n",
      "Epoch 20/300\n",
      "1169/1169 [==============================] - 0s 118us/sample - loss: 0.2032 - mean_absolute_error: 0.2577\n",
      "Epoch 21/300\n",
      "1169/1169 [==============================] - 0s 213us/sample - loss: 0.2225 - mean_absolute_error: 0.2811\n",
      "Epoch 22/300\n",
      "1169/1169 [==============================] - 0s 190us/sample - loss: 0.1919 - mean_absolute_error: 0.2560\n",
      "Epoch 23/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.2666 - mean_absolute_error: 0.3192\n",
      "Epoch 24/300\n",
      "1169/1169 [==============================] - 0s 106us/sample - loss: 0.2203 - mean_absolute_error: 0.2624\n",
      "Epoch 25/300\n",
      "1169/1169 [==============================] - 0s 153us/sample - loss: 0.2134 - mean_absolute_error: 0.2537\n",
      "Epoch 26/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1868 - mean_absolute_error: 0.2443\n",
      "Epoch 27/300\n",
      "1169/1169 [==============================] - 0s 198us/sample - loss: 0.1776 - mean_absolute_error: 0.2492\n",
      "Epoch 28/300\n",
      "1169/1169 [==============================] - 0s 153us/sample - loss: 0.1834 - mean_absolute_error: 0.2501\n",
      "Epoch 29/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.1767 - mean_absolute_error: 0.2258\n",
      "Epoch 30/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.1350 - mean_absolute_error: 0.2116\n",
      "Epoch 31/300\n",
      "1169/1169 [==============================] - 0s 121us/sample - loss: 0.1801 - mean_absolute_error: 0.2454\n",
      "Epoch 32/300\n",
      "1169/1169 [==============================] - 0s 137us/sample - loss: 0.1943 - mean_absolute_error: 0.2520\n",
      "Epoch 33/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2186 - mean_absolute_error: 0.2504\n",
      "Epoch 34/300\n",
      "1169/1169 [==============================] - 0s 156us/sample - loss: 0.1867 - mean_absolute_error: 0.2397\n",
      "Epoch 35/300\n",
      "1169/1169 [==============================] - 0s 232us/sample - loss: 0.1920 - mean_absolute_error: 0.2443\n",
      "Epoch 36/300\n",
      "1169/1169 [==============================] - 0s 146us/sample - loss: 0.1768 - mean_absolute_error: 0.2264\n",
      "Epoch 37/300\n",
      "1169/1169 [==============================] - 0s 133us/sample - loss: 0.2184 - mean_absolute_error: 0.2672\n",
      "Epoch 38/300\n",
      "1169/1169 [==============================] - 0s 133us/sample - loss: 0.1696 - mean_absolute_error: 0.2318\n",
      "Epoch 39/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2119 - mean_absolute_error: 0.2465\n",
      "Epoch 40/300\n",
      "1169/1169 [==============================] - 0s 128us/sample - loss: 0.2072 - mean_absolute_error: 0.2468\n",
      "Epoch 41/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.2080 - mean_absolute_error: 0.2487\n",
      "Epoch 42/300\n",
      "1169/1169 [==============================] - 0s 141us/sample - loss: 0.2163 - mean_absolute_error: 0.2658\n",
      "Epoch 43/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.2319 - mean_absolute_error: 0.2962\n",
      "Epoch 44/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2205 - mean_absolute_error: 0.2649\n",
      "Epoch 45/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.2213 - mean_absolute_error: 0.2889\n",
      "Epoch 46/300\n",
      "1169/1169 [==============================] - 0s 214us/sample - loss: 0.2263 - mean_absolute_error: 0.2838\n",
      "Epoch 47/300\n",
      "1169/1169 [==============================] - 0s 141us/sample - loss: 0.1797 - mean_absolute_error: 0.2415\n",
      "Epoch 48/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.1585 - mean_absolute_error: 0.2376\n",
      "Epoch 49/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.2105 - mean_absolute_error: 0.2628\n",
      "Epoch 50/300\n",
      "1169/1169 [==============================] - 0s 134us/sample - loss: 0.1866 - mean_absolute_error: 0.2512\n",
      "Epoch 51/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.1864 - mean_absolute_error: 0.2374\n",
      "Epoch 52/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.2139 - mean_absolute_error: 0.2599\n",
      "Epoch 53/300\n",
      "1169/1169 [==============================] - 0s 127us/sample - loss: 0.2071 - mean_absolute_error: 0.2710\n",
      "Epoch 54/300\n",
      "1169/1169 [==============================] - 0s 111us/sample - loss: 0.2201 - mean_absolute_error: 0.2826\n",
      "Epoch 55/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.1692 - mean_absolute_error: 0.2286\n",
      "Epoch 56/300\n",
      "1169/1169 [==============================] - 0s 132us/sample - loss: 0.2502 - mean_absolute_error: 0.3161\n",
      "Epoch 57/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.1912 - mean_absolute_error: 0.2738\n",
      "Epoch 58/300\n",
      "1169/1169 [==============================] - 0s 159us/sample - loss: 0.2231 - mean_absolute_error: 0.2531\n",
      "Epoch 59/300\n",
      "1169/1169 [==============================] - 0s 186us/sample - loss: 0.2248 - mean_absolute_error: 0.2678\n",
      "Epoch 60/300\n",
      "1169/1169 [==============================] - 0s 137us/sample - loss: 0.1938 - mean_absolute_error: 0.2649\n",
      "Epoch 61/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2215 - mean_absolute_error: 0.2871\n",
      "Epoch 62/300\n",
      "1169/1169 [==============================] - 0s 122us/sample - loss: 0.1720 - mean_absolute_error: 0.2290\n",
      "Epoch 63/300\n",
      "1169/1169 [==============================] - 0s 112us/sample - loss: 0.1997 - mean_absolute_error: 0.2434\n",
      "Epoch 64/300\n",
      "1169/1169 [==============================] - 0s 132us/sample - loss: 0.2569 - mean_absolute_error: 0.2965\n",
      "Epoch 65/300\n",
      "1169/1169 [==============================] - 0s 128us/sample - loss: 0.2082 - mean_absolute_error: 0.2623\n",
      "Epoch 66/300\n",
      "1169/1169 [==============================] - 0s 118us/sample - loss: 0.1922 - mean_absolute_error: 0.2392\n",
      "Epoch 67/300\n",
      "1169/1169 [==============================] - 0s 116us/sample - loss: 0.1833 - mean_absolute_error: 0.2357\n",
      "Epoch 68/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1823 - mean_absolute_error: 0.2539\n",
      "Epoch 69/300\n",
      "1169/1169 [==============================] - 0s 93us/sample - loss: 0.2078 - mean_absolute_error: 0.2523\n",
      "Epoch 70/300\n",
      "1169/1169 [==============================] - 0s 196us/sample - loss: 0.2472 - mean_absolute_error: 0.2897\n",
      "Epoch 71/300\n",
      "1169/1169 [==============================] - 0s 159us/sample - loss: 0.1975 - mean_absolute_error: 0.2548\n",
      "Epoch 72/300\n",
      "1169/1169 [==============================] - 0s 133us/sample - loss: 0.2202 - mean_absolute_error: 0.2594\n",
      "Epoch 73/300\n",
      "1169/1169 [==============================] - 0s 90us/sample - loss: 0.3633 - mean_absolute_error: 0.3815\n",
      "Epoch 74/300\n",
      "1169/1169 [==============================] - 0s 122us/sample - loss: 0.3186 - mean_absolute_error: 0.3728\n",
      "Epoch 75/300\n",
      "1169/1169 [==============================] - 0s 176us/sample - loss: 0.2615 - mean_absolute_error: 0.3145\n",
      "Epoch 76/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.2195 - mean_absolute_error: 0.2846\n",
      "Epoch 77/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.2141 - mean_absolute_error: 0.2774\n",
      "Epoch 78/300\n",
      "1169/1169 [==============================] - 0s 138us/sample - loss: 0.2008 - mean_absolute_error: 0.2661\n",
      "Epoch 79/300\n",
      "1169/1169 [==============================] - 0s 138us/sample - loss: 0.1969 - mean_absolute_error: 0.2591\n",
      "Epoch 80/300\n",
      "1169/1169 [==============================] - 0s 163us/sample - loss: 0.1857 - mean_absolute_error: 0.2459\n",
      "Epoch 81/300\n",
      "1169/1169 [==============================] - 0s 190us/sample - loss: 0.2047 - mean_absolute_error: 0.2740\n",
      "Epoch 82/300\n",
      "1169/1169 [==============================] - 0s 122us/sample - loss: 0.2144 - mean_absolute_error: 0.2744\n",
      "Epoch 83/300\n",
      "1169/1169 [==============================] - 0s 99us/sample - loss: 0.1813 - mean_absolute_error: 0.2452\n",
      "Epoch 84/300\n",
      "1169/1169 [==============================] - 0s 189us/sample - loss: 0.2179 - mean_absolute_error: 0.2696\n",
      "Epoch 85/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.2285 - mean_absolute_error: 0.2917\n",
      "Epoch 86/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.1648 - mean_absolute_error: 0.2356\n",
      "Epoch 87/300\n",
      "1169/1169 [==============================] - 0s 212us/sample - loss: 0.1900 - mean_absolute_error: 0.2427\n",
      "Epoch 88/300\n",
      "1169/1169 [==============================] - 0s 183us/sample - loss: 0.1720 - mean_absolute_error: 0.2510\n",
      "Epoch 89/300\n",
      "1169/1169 [==============================] - 0s 129us/sample - loss: 0.1718 - mean_absolute_error: 0.2346\n",
      "Epoch 90/300\n",
      "1169/1169 [==============================] - 0s 134us/sample - loss: 0.1660 - mean_absolute_error: 0.2505\n",
      "Epoch 91/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2079 - mean_absolute_error: 0.2752\n",
      "Epoch 92/300\n",
      "1169/1169 [==============================] - 0s 134us/sample - loss: 0.2972 - mean_absolute_error: 0.3579\n",
      "Epoch 93/300\n",
      "1169/1169 [==============================] - 0s 93us/sample - loss: 0.1672 - mean_absolute_error: 0.2426\n",
      "Epoch 94/300\n",
      "1169/1169 [==============================] - 0s 193us/sample - loss: 0.1794 - mean_absolute_error: 0.2395\n",
      "Epoch 95/300\n",
      "1169/1169 [==============================] - 0s 185us/sample - loss: 0.2011 - mean_absolute_error: 0.2686\n",
      "Epoch 96/300\n",
      "1169/1169 [==============================] - 0s 122us/sample - loss: 0.2562 - mean_absolute_error: 0.2910\n",
      "Epoch 97/300\n",
      "1169/1169 [==============================] - 0s 102us/sample - loss: 0.2211 - mean_absolute_error: 0.2842\n",
      "Epoch 98/300\n",
      "1169/1169 [==============================] - 0s 108us/sample - loss: 0.2272 - mean_absolute_error: 0.2705\n",
      "Epoch 99/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.2093 - mean_absolute_error: 0.2674\n",
      "Epoch 100/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.1904 - mean_absolute_error: 0.2623\n",
      "Epoch 101/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1772 - mean_absolute_error: 0.2389\n",
      "Epoch 102/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.1748 - mean_absolute_error: 0.2424\n",
      "Epoch 103/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1844 - mean_absolute_error: 0.2602\n",
      "Epoch 104/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.1872 - mean_absolute_error: 0.2459\n",
      "Epoch 105/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2011 - mean_absolute_error: 0.2625\n",
      "Epoch 106/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.1831 - mean_absolute_error: 0.2539\n",
      "Epoch 107/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.1867 - mean_absolute_error: 0.2513\n",
      "Epoch 108/300\n",
      "1169/1169 [==============================] - 0s 135us/sample - loss: 0.2238 - mean_absolute_error: 0.2750\n",
      "Epoch 109/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.1810 - mean_absolute_error: 0.2559\n",
      "Epoch 110/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.1893 - mean_absolute_error: 0.2485\n",
      "Epoch 111/300\n",
      "1169/1169 [==============================] - 0s 189us/sample - loss: 0.1862 - mean_absolute_error: 0.2551\n",
      "Epoch 112/300\n",
      "1169/1169 [==============================] - 0s 191us/sample - loss: 0.1887 - mean_absolute_error: 0.2571\n",
      "Epoch 113/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.1868 - mean_absolute_error: 0.2482\n",
      "Epoch 114/300\n",
      "1169/1169 [==============================] - 0s 118us/sample - loss: 0.2003 - mean_absolute_error: 0.2674\n",
      "Epoch 115/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.1929 - mean_absolute_error: 0.2670\n",
      "Epoch 116/300\n",
      "1169/1169 [==============================] - 0s 109us/sample - loss: 0.1894 - mean_absolute_error: 0.2612\n",
      "Epoch 117/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.2340 - mean_absolute_error: 0.2778\n",
      "Epoch 118/300\n",
      "1169/1169 [==============================] - 0s 144us/sample - loss: 0.2007 - mean_absolute_error: 0.2643\n",
      "Epoch 119/300\n",
      "1169/1169 [==============================] - 0s 184us/sample - loss: 0.1948 - mean_absolute_error: 0.2546\n",
      "Epoch 120/300\n",
      "1169/1169 [==============================] - 0s 138us/sample - loss: 0.1758 - mean_absolute_error: 0.2361\n",
      "Epoch 121/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.2007 - mean_absolute_error: 0.2766\n",
      "Epoch 122/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2081 - mean_absolute_error: 0.2573\n",
      "Epoch 123/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.2077 - mean_absolute_error: 0.2653\n",
      "Epoch 124/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.1811 - mean_absolute_error: 0.2434\n",
      "Epoch 125/300\n",
      "1169/1169 [==============================] - 0s 192us/sample - loss: 0.1780 - mean_absolute_error: 0.2480\n",
      "Epoch 126/300\n",
      "1169/1169 [==============================] - 0s 192us/sample - loss: 0.2228 - mean_absolute_error: 0.2748\n",
      "Epoch 127/300\n",
      "1169/1169 [==============================] - 0s 112us/sample - loss: 0.2062 - mean_absolute_error: 0.2766\n",
      "Epoch 128/300\n",
      "1169/1169 [==============================] - 0s 139us/sample - loss: 0.2100 - mean_absolute_error: 0.2470\n",
      "Epoch 129/300\n",
      "1169/1169 [==============================] - 0s 162us/sample - loss: 0.1875 - mean_absolute_error: 0.2544\n",
      "Epoch 130/300\n",
      "1169/1169 [==============================] - 0s 213us/sample - loss: 0.1815 - mean_absolute_error: 0.2455\n",
      "Epoch 131/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.1954 - mean_absolute_error: 0.2476\n",
      "Epoch 132/300\n",
      "1169/1169 [==============================] - 0s 129us/sample - loss: 0.2377 - mean_absolute_error: 0.3125\n",
      "Epoch 133/300\n",
      "1169/1169 [==============================] - 0s 118us/sample - loss: 0.2117 - mean_absolute_error: 0.2796\n",
      "Epoch 134/300\n",
      "1169/1169 [==============================] - 0s 110us/sample - loss: 0.2196 - mean_absolute_error: 0.2745\n",
      "Epoch 135/300\n",
      "1169/1169 [==============================] - 0s 100us/sample - loss: 0.2427 - mean_absolute_error: 0.3133\n",
      "Epoch 136/300\n",
      "1169/1169 [==============================] - 0s 111us/sample - loss: 0.2023 - mean_absolute_error: 0.2647\n",
      "Epoch 137/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 121us/sample - loss: 0.1889 - mean_absolute_error: 0.2482\n",
      "Epoch 138/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.1992 - mean_absolute_error: 0.2615\n",
      "Epoch 139/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2222 - mean_absolute_error: 0.2901\n",
      "Epoch 140/300\n",
      "1169/1169 [==============================] - 0s 141us/sample - loss: 0.1983 - mean_absolute_error: 0.2801\n",
      "Epoch 141/300\n",
      "1169/1169 [==============================] - 0s 173us/sample - loss: 0.2008 - mean_absolute_error: 0.2493\n",
      "Epoch 142/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.2079 - mean_absolute_error: 0.2614\n",
      "Epoch 143/300\n",
      "1169/1169 [==============================] - 0s 121us/sample - loss: 0.1912 - mean_absolute_error: 0.2589\n",
      "Epoch 144/300\n",
      "1169/1169 [==============================] - 0s 102us/sample - loss: 0.1986 - mean_absolute_error: 0.2666\n",
      "Epoch 145/300\n",
      "1169/1169 [==============================] - 0s 198us/sample - loss: 0.2674 - mean_absolute_error: 0.3359\n",
      "Epoch 146/300\n",
      "1169/1169 [==============================] - 0s 150us/sample - loss: 0.1951 - mean_absolute_error: 0.2607\n",
      "Epoch 147/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.1726 - mean_absolute_error: 0.2612\n",
      "Epoch 148/300\n",
      "1169/1169 [==============================] - 0s 208us/sample - loss: 0.2127 - mean_absolute_error: 0.2685\n",
      "Epoch 149/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.1821 - mean_absolute_error: 0.2630\n",
      "Epoch 150/300\n",
      "1169/1169 [==============================] - 0s 181us/sample - loss: 0.2089 - mean_absolute_error: 0.2662\n",
      "Epoch 151/300\n",
      "1169/1169 [==============================] - 0s 159us/sample - loss: 0.1936 - mean_absolute_error: 0.2566\n",
      "Epoch 152/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.1980 - mean_absolute_error: 0.2597\n",
      "Epoch 153/300\n",
      "1169/1169 [==============================] - 0s 175us/sample - loss: 0.1495 - mean_absolute_error: 0.2307\n",
      "Epoch 154/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.1960 - mean_absolute_error: 0.2511\n",
      "Epoch 155/300\n",
      "1169/1169 [==============================] - 0s 135us/sample - loss: 0.1517 - mean_absolute_error: 0.2381\n",
      "Epoch 156/300\n",
      "1169/1169 [==============================] - 0s 179us/sample - loss: 0.1963 - mean_absolute_error: 0.2563\n",
      "Epoch 157/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.1996 - mean_absolute_error: 0.2519\n",
      "Epoch 158/300\n",
      "1169/1169 [==============================] - 0s 175us/sample - loss: 0.1682 - mean_absolute_error: 0.2367\n",
      "Epoch 159/300\n",
      "1169/1169 [==============================] - 0s 132us/sample - loss: 0.1895 - mean_absolute_error: 0.2563\n",
      "Epoch 160/300\n",
      "1169/1169 [==============================] - 0s 105us/sample - loss: 0.2071 - mean_absolute_error: 0.2647\n",
      "Epoch 161/300\n",
      "1169/1169 [==============================] - 0s 148us/sample - loss: 0.2115 - mean_absolute_error: 0.2791\n",
      "Epoch 162/300\n",
      "1169/1169 [==============================] - 0s 174us/sample - loss: 0.2185 - mean_absolute_error: 0.2773\n",
      "Epoch 163/300\n",
      "1169/1169 [==============================] - 0s 99us/sample - loss: 0.1931 - mean_absolute_error: 0.2583\n",
      "Epoch 164/300\n",
      "1169/1169 [==============================] - 0s 173us/sample - loss: 0.1720 - mean_absolute_error: 0.2423\n",
      "Epoch 165/300\n",
      "1169/1169 [==============================] - 0s 135us/sample - loss: 0.2121 - mean_absolute_error: 0.2569\n",
      "Epoch 166/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2245 - mean_absolute_error: 0.2842\n",
      "Epoch 167/300\n",
      "1169/1169 [==============================] - 0s 177us/sample - loss: 0.2030 - mean_absolute_error: 0.2612\n",
      "Epoch 168/300\n",
      "1169/1169 [==============================] - 0s 138us/sample - loss: 0.2036 - mean_absolute_error: 0.2671\n",
      "Epoch 169/300\n",
      "1169/1169 [==============================] - 0s 145us/sample - loss: 0.1572 - mean_absolute_error: 0.2340\n",
      "Epoch 170/300\n",
      "1169/1169 [==============================] - 0s 142us/sample - loss: 0.2011 - mean_absolute_error: 0.2704\n",
      "Epoch 171/300\n",
      "1169/1169 [==============================] - 0s 109us/sample - loss: 0.1799 - mean_absolute_error: 0.2372\n",
      "Epoch 172/300\n",
      "1169/1169 [==============================] - 0s 170us/sample - loss: 0.2222 - mean_absolute_error: 0.2845\n",
      "Epoch 173/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.2431 - mean_absolute_error: 0.2904\n",
      "Epoch 174/300\n",
      "1169/1169 [==============================] - 0s 174us/sample - loss: 0.2219 - mean_absolute_error: 0.2740\n",
      "Epoch 175/300\n",
      "1169/1169 [==============================] - 0s 128us/sample - loss: 0.2208 - mean_absolute_error: 0.2766\n",
      "Epoch 176/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.1880 - mean_absolute_error: 0.2590\n",
      "Epoch 177/300\n",
      "1169/1169 [==============================] - 0s 163us/sample - loss: 0.2676 - mean_absolute_error: 0.3230\n",
      "Epoch 178/300\n",
      "1169/1169 [==============================] - 0s 106us/sample - loss: 0.3574 - mean_absolute_error: 0.4233\n",
      "Epoch 179/300\n",
      "1169/1169 [==============================] - 0s 204us/sample - loss: 0.2755 - mean_absolute_error: 0.3170\n",
      "Epoch 180/300\n",
      "1169/1169 [==============================] - 0s 133us/sample - loss: 0.2198 - mean_absolute_error: 0.2867\n",
      "Epoch 181/300\n",
      "1169/1169 [==============================] - 0s 142us/sample - loss: 0.1704 - mean_absolute_error: 0.2548\n",
      "Epoch 182/300\n",
      "1169/1169 [==============================] - 0s 173us/sample - loss: 0.1813 - mean_absolute_error: 0.2486\n",
      "Epoch 183/300\n",
      "1169/1169 [==============================] - 0s 106us/sample - loss: 0.1973 - mean_absolute_error: 0.2672\n",
      "Epoch 184/300\n",
      "1169/1169 [==============================] - 0s 170us/sample - loss: 0.2136 - mean_absolute_error: 0.2692\n",
      "Epoch 185/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.2017 - mean_absolute_error: 0.2638\n",
      "Epoch 186/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.1967 - mean_absolute_error: 0.2518\n",
      "Epoch 187/300\n",
      "1169/1169 [==============================] - 0s 156us/sample - loss: 0.2372 - mean_absolute_error: 0.2962\n",
      "Epoch 188/300\n",
      "1169/1169 [==============================] - 0s 103us/sample - loss: 0.1865 - mean_absolute_error: 0.2532\n",
      "Epoch 189/300\n",
      "1169/1169 [==============================] - 0s 118us/sample - loss: 0.2176 - mean_absolute_error: 0.2694\n",
      "Epoch 190/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.1915 - mean_absolute_error: 0.2551\n",
      "Epoch 191/300\n",
      "1169/1169 [==============================] - 0s 111us/sample - loss: 0.2070 - mean_absolute_error: 0.2715\n",
      "Epoch 192/300\n",
      "1169/1169 [==============================] - 0s 156us/sample - loss: 0.2156 - mean_absolute_error: 0.2578\n",
      "Epoch 193/300\n",
      "1169/1169 [==============================] - 0s 170us/sample - loss: 0.2150 - mean_absolute_error: 0.2878\n",
      "Epoch 194/300\n",
      "1169/1169 [==============================] - 0s 132us/sample - loss: 0.2121 - mean_absolute_error: 0.2769\n",
      "Epoch 195/300\n",
      "1169/1169 [==============================] - 0s 163us/sample - loss: 0.1796 - mean_absolute_error: 0.2397\n",
      "Epoch 196/300\n",
      "1169/1169 [==============================] - 0s 153us/sample - loss: 0.1816 - mean_absolute_error: 0.2511\n",
      "Epoch 197/300\n",
      "1169/1169 [==============================] - 0s 150us/sample - loss: 0.2024 - mean_absolute_error: 0.2669\n",
      "Epoch 198/300\n",
      "1169/1169 [==============================] - 0s 189us/sample - loss: 0.1864 - mean_absolute_error: 0.2450\n",
      "Epoch 199/300\n",
      "1169/1169 [==============================] - 0s 134us/sample - loss: 0.2319 - mean_absolute_error: 0.2919\n",
      "Epoch 200/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.2227 - mean_absolute_error: 0.2734\n",
      "Epoch 201/300\n",
      "1169/1169 [==============================] - 0s 117us/sample - loss: 0.1678 - mean_absolute_error: 0.2461\n",
      "Epoch 202/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2013 - mean_absolute_error: 0.2517\n",
      "Epoch 203/300\n",
      "1169/1169 [==============================] - 0s 179us/sample - loss: 0.1935 - mean_absolute_error: 0.2503\n",
      "Epoch 204/300\n",
      "1169/1169 [==============================] - 0s 150us/sample - loss: 0.2185 - mean_absolute_error: 0.2779\n",
      "Epoch 205/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.2539 - mean_absolute_error: 0.2991\n",
      "Epoch 206/300\n",
      "1169/1169 [==============================] - 0s 137us/sample - loss: 0.2546 - mean_absolute_error: 0.3019\n",
      "Epoch 207/300\n",
      "1169/1169 [==============================] - 0s 166us/sample - loss: 0.2060 - mean_absolute_error: 0.2678\n",
      "Epoch 208/300\n",
      "1169/1169 [==============================] - 0s 118us/sample - loss: 0.2033 - mean_absolute_error: 0.2619\n",
      "Epoch 209/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2054 - mean_absolute_error: 0.2531\n",
      "Epoch 210/300\n",
      "1169/1169 [==============================] - 0s 193us/sample - loss: 0.1715 - mean_absolute_error: 0.2405\n",
      "Epoch 211/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.2128 - mean_absolute_error: 0.2731\n",
      "Epoch 212/300\n",
      "1169/1169 [==============================] - 0s 111us/sample - loss: 0.2321 - mean_absolute_error: 0.3057\n",
      "Epoch 213/300\n",
      "1169/1169 [==============================] - 0s 146us/sample - loss: 0.1829 - mean_absolute_error: 0.2420\n",
      "Epoch 214/300\n",
      "1169/1169 [==============================] - 0s 162us/sample - loss: 0.2095 - mean_absolute_error: 0.2696\n",
      "Epoch 215/300\n",
      "1169/1169 [==============================] - 0s 128us/sample - loss: 0.1665 - mean_absolute_error: 0.2394\n",
      "Epoch 216/300\n",
      "1169/1169 [==============================] - 0s 181us/sample - loss: 0.1692 - mean_absolute_error: 0.2342\n",
      "Epoch 217/300\n",
      "1169/1169 [==============================] - 0s 127us/sample - loss: 0.2022 - mean_absolute_error: 0.2536\n",
      "Epoch 218/300\n",
      "1169/1169 [==============================] - 0s 98us/sample - loss: 0.2055 - mean_absolute_error: 0.2717\n",
      "Epoch 219/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.2112 - mean_absolute_error: 0.2709\n",
      "Epoch 220/300\n",
      "1169/1169 [==============================] - 0s 100us/sample - loss: 0.1781 - mean_absolute_error: 0.2471\n",
      "Epoch 221/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1772 - mean_absolute_error: 0.2595\n",
      "Epoch 222/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.1974 - mean_absolute_error: 0.2648\n",
      "Epoch 223/300\n",
      "1169/1169 [==============================] - 0s 108us/sample - loss: 0.2379 - mean_absolute_error: 0.2732\n",
      "Epoch 224/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.2708 - mean_absolute_error: 0.3213\n",
      "Epoch 225/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.2172 - mean_absolute_error: 0.2708\n",
      "Epoch 226/300\n",
      "1169/1169 [==============================] - 0s 132us/sample - loss: 0.1984 - mean_absolute_error: 0.2612\n",
      "Epoch 227/300\n",
      "1169/1169 [==============================] - 0s 102us/sample - loss: 0.1865 - mean_absolute_error: 0.2584\n",
      "Epoch 228/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.2136 - mean_absolute_error: 0.2710\n",
      "Epoch 229/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.1931 - mean_absolute_error: 0.2470\n",
      "Epoch 230/300\n",
      "1169/1169 [==============================] - 0s 115us/sample - loss: 0.2236 - mean_absolute_error: 0.2880\n",
      "Epoch 231/300\n",
      "1169/1169 [==============================] - 0s 128us/sample - loss: 0.2343 - mean_absolute_error: 0.2862\n",
      "Epoch 232/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.2904 - mean_absolute_error: 0.3527\n",
      "Epoch 233/300\n",
      "1169/1169 [==============================] - 0s 105us/sample - loss: 0.2162 - mean_absolute_error: 0.2627\n",
      "Epoch 234/300\n",
      "1169/1169 [==============================] - 0s 133us/sample - loss: 0.1868 - mean_absolute_error: 0.2494\n",
      "Epoch 235/300\n",
      "1169/1169 [==============================] - 0s 136us/sample - loss: 0.1985 - mean_absolute_error: 0.2599\n",
      "Epoch 236/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.1742 - mean_absolute_error: 0.2462\n",
      "Epoch 237/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.2266 - mean_absolute_error: 0.2619\n",
      "Epoch 238/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.2499 - mean_absolute_error: 0.2952\n",
      "Epoch 239/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.1700 - mean_absolute_error: 0.2414\n",
      "Epoch 240/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.2272 - mean_absolute_error: 0.2643\n",
      "Epoch 241/300\n",
      "1169/1169 [==============================] - 0s 114us/sample - loss: 0.2023 - mean_absolute_error: 0.2573\n",
      "Epoch 242/300\n",
      "1169/1169 [==============================] - 0s 187us/sample - loss: 0.2502 - mean_absolute_error: 0.3047\n",
      "Epoch 243/300\n",
      "1169/1169 [==============================] - 0s 161us/sample - loss: 0.2251 - mean_absolute_error: 0.2786\n",
      "Epoch 244/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.2327 - mean_absolute_error: 0.2893\n",
      "Epoch 245/300\n",
      "1169/1169 [==============================] - 0s 120us/sample - loss: 0.2094 - mean_absolute_error: 0.2657\n",
      "Epoch 246/300\n",
      "1169/1169 [==============================] - 0s 136us/sample - loss: 0.1813 - mean_absolute_error: 0.2535\n",
      "Epoch 247/300\n",
      "1169/1169 [==============================] - 0s 130us/sample - loss: 0.2208 - mean_absolute_error: 0.2688\n",
      "Epoch 248/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.1948 - mean_absolute_error: 0.2608\n",
      "Epoch 249/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.1772 - mean_absolute_error: 0.2512\n",
      "Epoch 250/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.1845 - mean_absolute_error: 0.2468\n",
      "Epoch 251/300\n",
      "1169/1169 [==============================] - 0s 136us/sample - loss: 0.2084 - mean_absolute_error: 0.2651\n",
      "Epoch 252/300\n",
      "1169/1169 [==============================] - 0s 122us/sample - loss: 0.1984 - mean_absolute_error: 0.2513\n",
      "Epoch 253/300\n",
      "1169/1169 [==============================] - 0s 140us/sample - loss: 0.2293 - mean_absolute_error: 0.2765\n",
      "Epoch 254/300\n",
      "1169/1169 [==============================] - 0s 161us/sample - loss: 0.2105 - mean_absolute_error: 0.2697\n",
      "Epoch 255/300\n",
      "1169/1169 [==============================] - 0s 103us/sample - loss: 0.1954 - mean_absolute_error: 0.2566\n",
      "Epoch 256/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.2207 - mean_absolute_error: 0.2730\n",
      "Epoch 257/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.1726 - mean_absolute_error: 0.2495\n",
      "Epoch 258/300\n",
      "1169/1169 [==============================] - 0s 128us/sample - loss: 0.2543 - mean_absolute_error: 0.2952\n",
      "Epoch 259/300\n",
      "1169/1169 [==============================] - 0s 132us/sample - loss: 0.2071 - mean_absolute_error: 0.2705\n",
      "Epoch 260/300\n",
      "1169/1169 [==============================] - 0s 153us/sample - loss: 0.1886 - mean_absolute_error: 0.2654\n",
      "Epoch 261/300\n",
      "1169/1169 [==============================] - 0s 184us/sample - loss: 0.3035 - mean_absolute_error: 0.3347\n",
      "Epoch 262/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.2026 - mean_absolute_error: 0.2837\n",
      "Epoch 263/300\n",
      "1169/1169 [==============================] - 0s 109us/sample - loss: 0.2232 - mean_absolute_error: 0.2831\n",
      "Epoch 264/300\n",
      "1169/1169 [==============================] - 0s 121us/sample - loss: 0.2033 - mean_absolute_error: 0.2593\n",
      "Epoch 265/300\n",
      "1169/1169 [==============================] - 0s 213us/sample - loss: 0.2124 - mean_absolute_error: 0.2667\n",
      "Epoch 266/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.1602 - mean_absolute_error: 0.2309\n",
      "Epoch 267/300\n",
      "1169/1169 [==============================] - 0s 103us/sample - loss: 0.2210 - mean_absolute_error: 0.2889\n",
      "Epoch 268/300\n",
      "1169/1169 [==============================] - 0s 157us/sample - loss: 0.2073 - mean_absolute_error: 0.2675\n",
      "Epoch 269/300\n",
      "1169/1169 [==============================] - 0s 151us/sample - loss: 0.1984 - mean_absolute_error: 0.2739\n",
      "Epoch 270/300\n",
      "1169/1169 [==============================] - 0s 124us/sample - loss: 0.2029 - mean_absolute_error: 0.2693\n",
      "Epoch 271/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.2143 - mean_absolute_error: 0.2808\n",
      "Epoch 272/300\n",
      "1169/1169 [==============================] - 0s 102us/sample - loss: 0.1954 - mean_absolute_error: 0.2554\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1716 - mean_absolute_error: 0.2494\n",
      "Epoch 274/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.2249 - mean_absolute_error: 0.2623\n",
      "Epoch 275/300\n",
      "1169/1169 [==============================] - 0s 176us/sample - loss: 0.1976 - mean_absolute_error: 0.2656\n",
      "Epoch 276/300\n",
      "1169/1169 [==============================] - 0s 134us/sample - loss: 0.1812 - mean_absolute_error: 0.2416\n",
      "Epoch 277/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.1786 - mean_absolute_error: 0.2354\n",
      "Epoch 278/300\n",
      "1169/1169 [==============================] - 0s 175us/sample - loss: 0.2140 - mean_absolute_error: 0.2744\n",
      "Epoch 279/300\n",
      "1169/1169 [==============================] - 0s 136us/sample - loss: 0.1813 - mean_absolute_error: 0.2555\n",
      "Epoch 280/300\n",
      "1169/1169 [==============================] - 0s 117us/sample - loss: 0.2009 - mean_absolute_error: 0.2558\n",
      "Epoch 281/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.1746 - mean_absolute_error: 0.2485\n",
      "Epoch 282/300\n",
      "1169/1169 [==============================] - 0s 108us/sample - loss: 0.1999 - mean_absolute_error: 0.2579\n",
      "Epoch 283/300\n",
      "1169/1169 [==============================] - 0s 107us/sample - loss: 0.1865 - mean_absolute_error: 0.2509\n",
      "Epoch 284/300\n",
      "1169/1169 [==============================] - 0s 111us/sample - loss: 0.1924 - mean_absolute_error: 0.2544\n",
      "Epoch 285/300\n",
      "1169/1169 [==============================] - 0s 176us/sample - loss: 0.1820 - mean_absolute_error: 0.2471\n",
      "Epoch 286/300\n",
      "1169/1169 [==============================] - 0s 162us/sample - loss: 0.2288 - mean_absolute_error: 0.2853\n",
      "Epoch 287/300\n",
      "1169/1169 [==============================] - 0s 112us/sample - loss: 0.2503 - mean_absolute_error: 0.2925\n",
      "Epoch 288/300\n",
      "1169/1169 [==============================] - 0s 123us/sample - loss: 0.1924 - mean_absolute_error: 0.2536\n",
      "Epoch 289/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.1691 - mean_absolute_error: 0.2384\n",
      "Epoch 290/300\n",
      "1169/1169 [==============================] - 0s 111us/sample - loss: 0.1831 - mean_absolute_error: 0.2464\n",
      "Epoch 291/300\n",
      "1169/1169 [==============================] - 0s 192us/sample - loss: 0.2713 - mean_absolute_error: 0.3134\n",
      "Epoch 292/300\n",
      "1169/1169 [==============================] - 0s 131us/sample - loss: 0.2118 - mean_absolute_error: 0.2851\n",
      "Epoch 293/300\n",
      "1169/1169 [==============================] - 0s 119us/sample - loss: 0.1986 - mean_absolute_error: 0.2655\n",
      "Epoch 294/300\n",
      "1169/1169 [==============================] - 0s 158us/sample - loss: 0.1778 - mean_absolute_error: 0.2413\n",
      "Epoch 295/300\n",
      "1169/1169 [==============================] - 0s 145us/sample - loss: 0.1706 - mean_absolute_error: 0.2374\n",
      "Epoch 296/300\n",
      "1169/1169 [==============================] - 0s 102us/sample - loss: 0.2023 - mean_absolute_error: 0.2647\n",
      "Epoch 297/300\n",
      "1169/1169 [==============================] - 0s 125us/sample - loss: 0.1949 - mean_absolute_error: 0.2573\n",
      "Epoch 298/300\n",
      "1169/1169 [==============================] - 0s 126us/sample - loss: 0.1915 - mean_absolute_error: 0.2597\n",
      "Epoch 299/300\n",
      "1169/1169 [==============================] - 0s 113us/sample - loss: 0.2270 - mean_absolute_error: 0.2691\n",
      "Epoch 300/300\n",
      "1169/1169 [==============================] - 0s 166us/sample - loss: 0.1931 - mean_absolute_error: 0.2571\n",
      "R-squared 0.9141086066775709\n",
      "Mean Squared Error 0.20017849955013034\n"
     ]
    }
   ],
   "source": [
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        print(f'\\ntimeperiod: {period}, resolution: {res}')\n",
    "        \n",
    "        df = prediction_data.get(period).get(res)\n",
    "        columns = get_columns(df, \"cos\")\n",
    "\n",
    "        params= params_fnn.get(period).get(res)\n",
    "        model = create_nn(\n",
    "                input_size= params['regressor__model__input_size'], \n",
    "                act_function = params['regressor__model__act_function'], \n",
    "                decrease_func = exp_dec_func, \n",
    "                factor = params['regressor__model__factor'], \n",
    "                first_layer_factor = params['regressor__model__first_layer_factor'],\n",
    "                optimizer = params['regressor__model__optimizer'],\n",
    "                loss = params['regressor__model__loss'],\n",
    "                metrics = params['regressor__model__metrics'],\n",
    "                dropout_rate = params['regressor__model__dropout_rate'],\n",
    "                #kernel_regularizer,\n",
    "                learning_rate = params['regressor__model__learning_rate']\n",
    "        )\n",
    "        params_train={\n",
    "            'epochs' : 300,\n",
    "            'batch_size' : params['regressor__model__batch_size']\n",
    "        }\n",
    "        \n",
    "        sorted_train_test_split(df[columns], df[['number_of_trips']], 0.15, model, train_nn, params=params_train)\n",
    "        break\n",
    "        #joblib.dump(model, f'Models/SVR/LSVR/models/ksvr_{period}_{res}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of  the different time/spaitla bin combinations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the different test/train split techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aanalyize the models with XAI methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply different NN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional NN (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent NN (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory Networks (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernalized NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare SVM and NN models in terms of predictive performance and computation time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
