{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#List-available-GPUs\" data-toc-modified-id=\"List-available-GPUs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>List available GPUs</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Transformations\" data-toc-modified-id=\"Data-Transformations-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Data Transformations</a></span></li><li><span><a href=\"#Test/Train-split-Techniques\" data-toc-modified-id=\"Test/Train-split-Techniques-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Test/Train split Techniques</a></span></li></ul></li><li><span><a href=\"#Additional-Pre-Processing\" data-toc-modified-id=\"Additional-Pre-Processing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Additional Pre-Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deploy-One-Hot-Encoding\" data-toc-modified-id=\"Deploy-One-Hot-Encoding-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Deploy One-Hot-Encoding</a></span></li><li><span><a href=\"#Create-Feature_Sets\" data-toc-modified-id=\"Create-Feature_Sets-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Create Feature_Sets</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machines\" data-toc-modified-id=\"Support-Vector-Machines-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Support Vector Machines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Perform-Grid-search\" data-toc-modified-id=\"Perform-Grid-search-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Perform Grid search</a></span></li><li><span><a href=\"#Train-the-models-with-different-time/spatial\" data-toc-modified-id=\"Train-the-models-with-different-time/spatial-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Train the models with different time/spatial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Batch-Split-k-fold-Cross-Validation\" data-toc-modified-id=\"Batch-Split-k-fold-Cross-Validation-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Batch Split k-fold Cross Validation</a></span></li><li><span><a href=\"#Sliding-Window-cross-Validation\" data-toc-modified-id=\"Sliding-Window-cross-Validation-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Sliding Window cross Validation</a></span></li><li><span><a href=\"#Expanding-Window-Split\" data-toc-modified-id=\"Expanding-Window-Split-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Expanding Window Split</a></span></li><li><span><a href=\"#Start-End-Split\" data-toc-modified-id=\"Start-End-Split-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Start End Split</a></span></li></ul></li><li><span><a href=\"#Compare-the-results-of-the-different-time/spaitla-bin-combinations\" data-toc-modified-id=\"Compare-the-results-of-the-different-time/spaitla-bin-combinations-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Compare the results of the different time/spaitla bin combinations</a></span></li><li><span><a href=\"#Analyize-the-models-with-XAI-methods\" data-toc-modified-id=\"Analyize-the-models-with-XAI-methods-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Analyize the models with XAI methods</a></span></li></ul></li><li><span><a href=\"#Neural-Networks\" data-toc-modified-id=\"Neural-Networks-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Train-the-models-with-different-time/spatial-bins-and-different-test/train-spilt-techniques\" data-toc-modified-id=\"Train-the-models-with-different-time/spatial-bins-and-different-test/train-spilt-techniques-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Train the models with different time/spatial bins and different test/train spilt techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Batch-Split-k-fold-Cross-Validation\" data-toc-modified-id=\"Batch-Split-k-fold-Cross-Validation-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Batch Split k-fold Cross Validation</a></span></li><li><span><a href=\"#Sliding-Window-cross-Validation\" data-toc-modified-id=\"Sliding-Window-cross-Validation-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Sliding Window cross Validation</a></span></li><li><span><a href=\"#Expanding-Window-Split\" data-toc-modified-id=\"Expanding-Window-Split-7.2.3\"><span class=\"toc-item-num\">7.2.3&nbsp;&nbsp;</span>Expanding Window Split</a></span></li><li><span><a href=\"#Start-End-Split\" data-toc-modified-id=\"Start-End-Split-7.2.4\"><span class=\"toc-item-num\">7.2.4&nbsp;&nbsp;</span>Start End Split</a></span></li></ul></li><li><span><a href=\"#Compare-the-results-of--the-different-time/spaitla-bin-combinations\" data-toc-modified-id=\"Compare-the-results-of--the-different-time/spaitla-bin-combinations-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Compare the results of  the different time/spaitla bin combinations</a></span></li><li><span><a href=\"#Compare-the-different-test/train-split-techniques\" data-toc-modified-id=\"Compare-the-different-test/train-split-techniques-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Compare the different test/train split techniques</a></span></li><li><span><a href=\"#Aanalyize-the-models-with-XAI-methods\" data-toc-modified-id=\"Aanalyize-the-models-with-XAI-methods-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Aanalyize the models with XAI methods</a></span></li><li><span><a href=\"#Apply-different-NN-architectures\" data-toc-modified-id=\"Apply-different-NN-architectures-7.6\"><span class=\"toc-item-num\">7.6&nbsp;&nbsp;</span>Apply different NN architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convolutional-NN-(CNN)\" data-toc-modified-id=\"Convolutional-NN-(CNN)-7.6.1\"><span class=\"toc-item-num\">7.6.1&nbsp;&nbsp;</span>Convolutional NN (CNN)</a></span></li><li><span><a href=\"#Recurrent-NN-(RNN)\" data-toc-modified-id=\"Recurrent-NN-(RNN)-7.6.2\"><span class=\"toc-item-num\">7.6.2&nbsp;&nbsp;</span>Recurrent NN (RNN)</a></span></li><li><span><a href=\"#Long-Short-Term-Memory-Networks-(LSTM)\" data-toc-modified-id=\"Long-Short-Term-Memory-Networks-(LSTM)-7.6.3\"><span class=\"toc-item-num\">7.6.3&nbsp;&nbsp;</span>Long Short-Term Memory Networks (LSTM)</a></span></li><li><span><a href=\"#Kernalized-NN\" data-toc-modified-id=\"Kernalized-NN-7.6.4\"><span class=\"toc-item-num\">7.6.4&nbsp;&nbsp;</span>Kernalized NN</a></span></li><li><span><a href=\"#Comparison-of-the-results\" data-toc-modified-id=\"Comparison-of-the-results-7.6.5\"><span class=\"toc-item-num\">7.6.5&nbsp;&nbsp;</span>Comparison of the results</a></span></li></ul></li></ul></li><li><span><a href=\"#Compare-SVM-and-NN-models-in-terms-of-predictive-performance-and-computation-time\" data-toc-modified-id=\"Compare-SVM-and-NN-models-in-terms-of-predictive-performance-and-computation-time-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Compare SVM and NN models in terms of predictive performance and computation time</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from dask_ml.model_selection import GridSearchCV as DaskGridSearchCV\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import time\n",
    "\n",
    "import shap\n",
    "import lime\n",
    "\n",
    "import joblib\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#print(\"Num GPUs Available:\", len([x for x in device_lib.list_local_devices() if x.device_type == 'GPU']))\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPU found.\")\n",
    "else:\n",
    "    print(f\"GPUs found: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"Device: {gpu.name}\")\n",
    "        print(gpu.device_type)\n",
    "        details = tf.config.experimental.get_memory_info(gpu.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = [1, 2, 6, 24] # time bins we want to predict the demand for\n",
    "resolution = ['h3_res_4', 'h3_res_6', 'h3_res_8'] # spatial resolution we want to predict the demand for\n",
    "\n",
    "prediction_data={}\n",
    "for period in time_periods:\n",
    "    res_data={}\n",
    "    for res in resolution:\n",
    "        res_data[res]=pd.read_csv(f'../data/{period}hours_{res}.csv', \n",
    "                                  parse_dates=['trip_start_timestamp'],\n",
    "                                  #index_col=\"trip_start_timestamp\"\n",
    "                                 )\n",
    "    prediction_data[period]=res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>h3_res_4</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>number_of_trips</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>lagged_1h</th>\n",
       "      <th>lagged_1day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>8426645ffffffff</td>\n",
       "      <td>-20.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>842664dffffffff</td>\n",
       "      <td>-20.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>8427593ffffffff</td>\n",
       "      <td>-20.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>8426645ffffffff</td>\n",
       "      <td>-18.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269797</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>842664dffffffff</td>\n",
       "      <td>-19.374470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269797</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_start_timestamp         h3_res_4  temperature  precipitation  \\\n",
       "0  2018-01-01 00:00:00  8426645ffffffff   -20.555556            0.0   \n",
       "1  2018-01-01 00:00:00  842664dffffffff   -20.555556            0.0   \n",
       "2  2018-01-01 00:00:00  8427593ffffffff   -20.555556            0.0   \n",
       "3  2018-01-01 01:00:00  8426645ffffffff   -18.333333            0.0   \n",
       "4  2018-01-01 01:00:00  842664dffffffff   -19.374470            0.0   \n",
       "\n",
       "   number_of_trips  weekday  month  hour  hour_sin  hour_cos   weekday_sin  \\\n",
       "0                2      1.0    1.0   0.0  0.000000  1.000000 -2.449294e-16   \n",
       "1             2321      1.0    1.0   0.0  0.000000  1.000000 -2.449294e-16   \n",
       "2               35      1.0    1.0   0.0  0.000000  1.000000 -2.449294e-16   \n",
       "3                2      1.0    1.0   1.0  0.269797  0.962917 -2.449294e-16   \n",
       "4             4192      1.0    1.0   1.0  0.269797  0.962917 -2.449294e-16   \n",
       "\n",
       "   weekday_cos  lagged_1h  lagged_1day  \n",
       "0          1.0        NaN          NaN  \n",
       "1          1.0        NaN          NaN  \n",
       "2          1.0        NaN          NaN  \n",
       "3          1.0        2.0          NaN  \n",
       "4          1.0     2321.0          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data.get(1).get('h3_res_4').head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Method that prepares the data for training (split the data/)\n",
    "    param X: feature data to be prepared\n",
    "    param Y: target data to be prepared\n",
    "    param train_index: index that defines the split for trainig data\n",
    "    param val_index: index that defines the split for target data\n",
    "    returns X_train, Y_train, X_val, Y_val: prepared training & validation data\n",
    "    '''\n",
    "    Scaler=StandardScaler()\n",
    "    \n",
    "    X_train = Scaler.fit_transform(X_train)\n",
    "    Y_train = Scaler.fit_transform(Y_train)\n",
    "    \n",
    "    X_test = Scaler.fit_transform(X_test)\n",
    "    Y_test = Scaler.fit_transform(Y_test)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def train_nn(X_train, Y_train, X_val, Y_val, model, params):\n",
    "    '''\n",
    "    This method compiles and trains a neural network with the given data and parameters\n",
    "    param X_train: Training data-set\n",
    "    param Y_train: Target variable for training\n",
    "    param X_val:   Test data-set\n",
    "    param y_val:   Target variable for validation\n",
    "    param model:   NN to be trained\n",
    "    param params:  Parameters to compile and fit the NN\n",
    "    returns:       Nothing     \n",
    "    '''\n",
    "    model.compile(\n",
    "        optimizer=params.get(\"optimizer\"),\n",
    "        loss=params.get(\"loss\"),\n",
    "        metrics=params.get(\"metrics\"),\n",
    "    )\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        batch_size=params.get(\"batch_size\"),\n",
    "        epochs=params.get(\"epochs\"),\n",
    "        #verbose=params.get(\"verbose\"),\n",
    "    )\n",
    "    Y_pred=model.predict(X_val)\n",
    "    r2 = r2_score(Y_val, Y_pred)\n",
    "    MAE = mean_absolute_error(Y_val, Y_pred)\n",
    "    print(f\"R-squared {r2}\")\n",
    "    print(f\"Mean Squared Error {MAE}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def train_lsvr(X_train, Y_train, X_val, Y_val, model, params):\n",
    "    '''\n",
    "    This method compiles and trains a SVM with the given data and parameters\n",
    "    param X_train: Training data-set\n",
    "    param Y_train: Target variable for training\n",
    "    param X_val:   Test data-set\n",
    "    param y_val:   Target variable for validation\n",
    "    param model:   SVM to be trained\n",
    "    param params:  Parameters to train the SVM\n",
    "    returns:       Nothing    \n",
    "    '''\n",
    "    model.set_params(\n",
    "              epsilon = params.get('regressor__model__epsilon'),\n",
    "              C = params.get('regressor__model__C'),\n",
    "              max_iter = 5000\n",
    "    )\n",
    "    model.fit(X_train, \n",
    "              Y_train.reshape(len(Y_train))\n",
    "             )\n",
    "    Y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(Y_val, Y_pred)\n",
    "    MAE = mean_absolute_error(Y_val, Y_pred)\n",
    "    print(f\"R-squared {r2}\")\n",
    "    print(f\"Mean Squared Error {MAE}\")\n",
    "\n",
    "\n",
    "def create_date_list(delta):\n",
    "    '''\n",
    "    This method creates a list of dates (2018-2019) \n",
    "    depending on the delta\n",
    "    params delta: determines break between dates\n",
    "    returns:      list of dates \n",
    "    '''\n",
    "    # create a startdate\n",
    "    start = pd.to_datetime(\"2018-01-01\", format=\"%Y-%m-%d\")\n",
    "    # create the enddate\n",
    "    #end = pd.to_datetime(\"2018-12-31\", format=\"%Y-%m-%d\")\n",
    "    end = pd.to_datetime(\"2018-01-20\", format=\"%Y-%m-%d\")\n",
    "    # create timedelta to increase days\n",
    "    next_date = timedelta(days=delta)\n",
    "    list_dates=[]\n",
    "    \n",
    "    while start <= end:\n",
    "        \n",
    "        # add date to list\n",
    "        list_dates.append(start)\n",
    "        # increase date by one day\n",
    "        start = start + next_date\n",
    "    list_dates.append(end)\n",
    "    \n",
    "    return list_dates\n",
    "\n",
    "\n",
    "def create_batch_split(X,Y, date_list, arr):\n",
    "    '''\n",
    "    '''\n",
    "    X_train = X.copy()\n",
    "    Y_train = Y.copy()\n",
    "    X_test = pd.DataFrame()\n",
    "    Y_test = pd.DataFrame()\n",
    "    # Sort the arr to be able to delete entries with the index\n",
    "    arr = sorted(arr, reverse=True)\n",
    "    for element in arr:\n",
    "        # extract batch\n",
    "        batch_x = X.loc[(X.index < date_list[element]) & (X.index >= date_list[element] - timedelta(days=7))]\n",
    "        batch_y = Y.loc[(Y.index < date_list[element]) & (Y.index >= date_list[element] - timedelta(days=7))]\n",
    "        # add to the test sets\n",
    "        X_test = pd.concat([batch_x, X_test])\n",
    "        Y_test = pd.concat([batch_y, Y_test])\n",
    "        # delete from the training data set\n",
    "        X_train.drop(index=batch_x.index, inplace=True)\n",
    "        Y_train.drop(index=batch_y.index, inplace=True)\n",
    "        # Delete the elements from the date_list that have been already used for the test set\n",
    "        del date_list[element]\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def get_columns(df, subset):\n",
    "    features = list(df.columns)\n",
    "    if subset == \"cos\":\n",
    "        features.remove(\"weekday\")\n",
    "        features.remove(\"month\")\n",
    "        features.remove(\"hour\")\n",
    "    return features\n",
    "\n",
    "def create_nn(input_size, act_function, decrease_func, factor, first_layer_factor):\n",
    "    '''\n",
    "    This method returns a neural network architecture based on the given params\n",
    "    param input_size:          number of input features\n",
    "    param act_function:        activation function that should be used for the network\n",
    "    param decrease:            function decrease of neurons from layer to layer \n",
    "                               (determines also number of hidden layers)\n",
    "    param frist_layer_factor:  determines number of neurons in the first layer (multiplied by input_size)\n",
    "    returns:                   neural network\n",
    "    '''\n",
    "    nn = Sequential()\n",
    "    neurons = int(input_size * first_layer_factor)\n",
    "    nn.add(Dense(neurons, input_shape=(input_size,), activation=act_function))\n",
    "    counter = 1\n",
    "    while counter >0:\n",
    "        neurons = decrease_func(factor, input_size, counter)\n",
    "        if neurons <=1:\n",
    "            break\n",
    "        else:\n",
    "            nn.add(Dense(neurons, activation=act_function))\n",
    "            counter +=1\n",
    "    nn.add(Dense(1))\n",
    "    return nn\n",
    "\n",
    "\n",
    "def linear_dec_func(factor, neurons, counter):\n",
    "    '''\n",
    "    function to determin the number of neurons for the next layer (in this case linear)\n",
    "    param factor:  slope of the linear function\n",
    "    param neurons: number of neurons of the last layer\n",
    "    returns:       number of neruons for the next layer\n",
    "    '''\n",
    "    return (int((1-factor *counter) * neurons))\n",
    "    \n",
    "def exp_dec_func(factor, neurons, counter):\n",
    "    '''\n",
    "    function to determin the number of neurons for the next layer (in this case exponential)\n",
    "    param factor:  determins pace of decrease\n",
    "    param neurons: number of neurons of the last layer\n",
    "    returns:       number of neruons for the next layer\n",
    "    '''\n",
    "    return int(math.exp(-counter * factor) * neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Train split Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_k_fold_validation(k, X, Y, model, train_model, params):\n",
    "    '''\n",
    "    Method that trains and validate the model using k-fold validation\n",
    "    However, this method can disrupt the temporal patterns and data leakage occurs \n",
    "    due to the lagged time features\n",
    "    param k:      Number of folds (iterations)\n",
    "    param x:      Feature data\n",
    "    param y:      Target data\n",
    "    param model:  Model to be trained ()\n",
    "    returns:      Nothing\n",
    "    '''\n",
    "    # initialize the folds\n",
    "    k_fold = KFold(n_splits= k, random_state=47, shuffle=True)\n",
    "    # iteratre through all folds\n",
    "    for train_index, val_index in k_fold.split(X,Y):\n",
    "        # normalize data\n",
    "        X_train, Y_train, X_val, Y_val = normalize_data(\n",
    "            X.iloc[train_index],\n",
    "            Y.iloc[train_index].values.reshape(-1,1), \n",
    "            X.iloc[val_index], \n",
    "            Y.iloc[val_index].values.reshape(-1,1)\n",
    "        )\n",
    "        # train & validate the model\n",
    "        train_model(X_train=X_train, Y_train= Y_train, X_val=X_val, Y_val=Y_val,  model=model, params=params)\n",
    "\n",
    "        \n",
    "def batch_split_cross_validation(k, time_bin, X, Y, model, train_model, params):\n",
    "    '''\n",
    "    This method split the entire dataset into batches. Direct Data Leakage is avoided by disrupting\n",
    "    the chain of the lagged time feature between test and training set. Batches are cut on week and day level \n",
    "    depending on the granularity of the time bins.\n",
    "    param X:              feature data \n",
    "    param Y:              target data\n",
    "    param k_folds:        number of folds for k-fold validation\n",
    "    param time_bin:       granularity of the time bins\n",
    "    returns index_dict:   contains indicies to split for cross validation\n",
    "    '''\n",
    "    # if 24 split batches by weeks\n",
    "    if time_bin == 24:\n",
    "        date_list = create_date_list(7)    \n",
    "    # else split by days\n",
    "    else:\n",
    "        date_list = create_date_list(1)\n",
    "    # number of batches that are included in the test set\n",
    "    size_test_split = len(date_list) // k\n",
    "    for fold in range(0, k):\n",
    "        print(fold)\n",
    "        # pick random choices for the test data batches\n",
    "        if fold==k-1:\n",
    "            arr = np.random.choice(range(1, len(date_list)), len(date_list)-1, replace=False)\n",
    "        else: \n",
    "            arr = np.random.choice(range(1, len(date_list)), size_test_split, replace=False)   \n",
    "        # create training and test set with the batches\n",
    "        X_train, Y_train, X_test, Y_test = create_batch_split(X,Y, date_list, arr)\n",
    "        # normalize the data\n",
    "        X_train, Y_train, X_test, Y_test = normalize_data(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            X_test,\n",
    "            Y_test\n",
    "        )\n",
    "        # train & validate the model\n",
    "        train_model(X_train=X_train, Y_train= Y_train, X_val=X_test, Y_val=Y_test,  model=model, params=params)\n",
    "\n",
    "\n",
    "def sliding_window_cross_validation(X,Y,n_windows, model, train_model, params):\n",
    "    '''\n",
    "    This method uses sliding window technique to the split the data. The user specifies the size of the window and\n",
    "    the model is trained sequentially with each window until the last window. Future data is used to the evaluate the\n",
    "    model. This way ensures no data leakage into the test set\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "\n",
    "def sorted_train_test_split(X, Y, test_size, model, train_model, params):\n",
    "    '''\n",
    "    '''\n",
    "    # sort the entries in ascending order\n",
    "    X.sort_index(inplace=True)\n",
    "    Y.sort_index(inplace=True)\n",
    "    # get split index\n",
    "    test_index = int(len(X)*(1-test_size))-1\n",
    "    # normalize data\n",
    "    X_train, Y_train, X_val, Y_val = normalize_data(\n",
    "        X.iloc[:test_index],\n",
    "        Y.iloc[:test_index].values.reshape(-1,1), \n",
    "        X.iloc[test_index:], \n",
    "        Y.iloc[test_index:].values.reshape(-1,1)\n",
    "    )\n",
    "    # train & validate the model\n",
    "    train_model(X_train=X_train, Y_train= Y_train, X_val=X_val, Y_val=Y_val,  model=model, params=params)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "# encode the hexagons in dummy variables\n",
    "\n",
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        df = prediction_data.get(period).get(res)\n",
    "\n",
    "        df[f'lagged_1day'].fillna(df['number_of_trips'].mean(), inplace= True)\n",
    "        if period!=24:\n",
    "            df[f'lagged_{period}h'].fillna(df['number_of_trips'].mean(), inplace= True)\n",
    "        \n",
    "        encoded_data = encoder.fit_transform(df[[res]])\n",
    "        encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([res]))\n",
    "\n",
    "        #df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        df = pd.concat([df, encoded_df], axis=1).drop(res, axis=1)\n",
    "        df.set_index(\"trip_start_timestamp\", inplace=True);\n",
    "        \n",
    "        prediction_data[period][res] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature_Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_linear = {\n",
    "    'regressor__model__C': [0.1, 1, 10, 100, 150],\n",
    "    'regressor__model__epsilon': [0.01, 0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "param_grid_k = {\n",
    "    'regressor__model__C': [0.1, 1, 10, 100, 150],\n",
    "    'regressor__model__epsilon': [0.01, 0.1, 0.5, 1],\n",
    "    #'regressor__model__kernel': ['rbf','sigmoid', 'poly'],\n",
    "    'regressor__model__kernel': ['rbf', 'sigmoid'],\n",
    "    'regressor__model__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "    'regressor__model__coef0': [0, 0.1, 0.5, 1],  # Relevant for 'poly' and 'sigmoid' kernels\n",
    "    #'regressor__model__degree': [2, 3, 4]  # Only relevant for 'poly' kernel\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_sv(tss, scaler, model, params, name):\n",
    "    '''\n",
    "    param tss:     TimeSeriesSplitObject to perform gridsearch on a timeseries split\n",
    "    param scaler:  preferred scaler to rescale the data\n",
    "    param model:   model used in the GS\n",
    "    param params:  param gird for the GS\n",
    "    param name:    name to store the params with joblib\n",
    "    '''\n",
    "    for period in time_periods:\n",
    "        for res in resolution: \n",
    "            \n",
    "            print(f\"time period:{period}, resolution:{res}\")\n",
    "            df = prediction_data.get(period).get(res)\n",
    "\n",
    "            # create pipline to scale the data\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', scaler),\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "            # create TransformedTargetRegressor to scale target variable\n",
    "            ttr = TransformedTargetRegressor(\n",
    "                regressor = pipeline,\n",
    "                transformer = scaler\n",
    "            )\n",
    "\n",
    "            # create dask grid search object (dask to enable parallel computing)\n",
    "            Dask_GS = DaskGridSearchCV(\n",
    "                estimator=ttr,\n",
    "                param_grid=params,\n",
    "                cv=tss,\n",
    "                scoring='r2',\n",
    "                n_jobs=-1 #use a available cores\n",
    "            )\n",
    "\n",
    "            # use Client() for enable parallel computing with dask\n",
    "            try:\n",
    "                with Client() as client:\n",
    "\n",
    "                    num_cores = client.ncores()\n",
    "                    print(f\"Number of cores: {num_cores}\")\n",
    "                    print(f\"Dashboard link: {client.dashboard_link}\")\n",
    "\n",
    "                    start_time = time.time() # time computation time for the gridsearch\n",
    "                    warnings.filterwarnings('ignore', message='Liblinear failed to converge, increase the number of iterations.')\n",
    "                    Dask_GS.fit(df[get_columns(df,'cos')], df['number_of_trips']) # fit the grid search\n",
    "                    end_time = time.time()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Exception {e} occured, swtich to running only one job\")\n",
    "\n",
    "                Dask_GS.n_jobs=1\n",
    "\n",
    "                start_time = time.time() # time computation time for the gridsearch\n",
    "                warnings.filterwarnings('ignore', message='Liblinear failed to converge, increase the number of iterations.')\n",
    "                Dask_GS.fit(df[get_columns(df,'cos')], df['number_of_trips']) # fit the grid search\n",
    "                end_time = time.time()\n",
    "\n",
    "            print(f\"GridSearch took: {(end_time-start_time)/60} minuts\")\n",
    "            joblib.dump(Dask_GS.best_params_, f'Models/{name}_{period}_{res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=4)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time period:1, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:51861': 2, 'tcp://127.0.0.1:51866': 2, 'tcp://127.0.0.1:51869': 2, 'tcp://127.0.0.1:51872': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.07675371964772543 minuts\n",
      "time period:1, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:51931': 2, 'tcp://127.0.0.1:51932': 2, 'tcp://127.0.0.1:51937': 2, 'tcp://127.0.0.1:51938': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.09571054379145304 minuts\n",
      "time period:1, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:51983': 2, 'tcp://127.0.0.1:51998': 2, 'tcp://127.0.0.1:52001': 2, 'tcp://127.0.0.1:52004': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.8847964525222778 minuts\n",
      "time period:2, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:52061': 2, 'tcp://127.0.0.1:52062': 2, 'tcp://127.0.0.1:52063': 2, 'tcp://127.0.0.1:52070': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.06947422822316487 minuts\n",
      "time period:2, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:52131': 2, 'tcp://127.0.0.1:52132': 2, 'tcp://127.0.0.1:52137': 2, 'tcp://127.0.0.1:52140': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.08518587350845337 minuts\n",
      "time period:2, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:52184': 2, 'tcp://127.0.0.1:52199': 2, 'tcp://127.0.0.1:52202': 2, 'tcp://127.0.0.1:52203': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.6629190683364868 minuts\n",
      "time period:6, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:52260': 2, 'tcp://127.0.0.1:52261': 2, 'tcp://127.0.0.1:52262': 2, 'tcp://127.0.0.1:52269': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.07472935517628988 minuts\n",
      "time period:6, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:52330': 2, 'tcp://127.0.0.1:52333': 2, 'tcp://127.0.0.1:52334': 2, 'tcp://127.0.0.1:52339': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.07196836074193319 minuts\n",
      "time period:6, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:52401': 2, 'tcp://127.0.0.1:52402': 2, 'tcp://127.0.0.1:52403': 2, 'tcp://127.0.0.1:52406': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.4066664139429728 minuts\n",
      "time period:24, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:52453': 2, 'tcp://127.0.0.1:52466': 2, 'tcp://127.0.0.1:52469': 2, 'tcp://127.0.0.1:52472': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.06883330742518107 minuts\n",
      "time period:24, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:52519': 2, 'tcp://127.0.0.1:52534': 2, 'tcp://127.0.0.1:52537': 2, 'tcp://127.0.0.1:52538': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.06995135943094889 minuts\n",
      "time period:24, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:52595': 2, 'tcp://127.0.0.1:52602': 2, 'tcp://127.0.0.1:52603': 2, 'tcp://127.0.0.1:52608': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.16062875986099243 minuts\n"
     ]
    }
   ],
   "source": [
    "#SVR()\n",
    "grid_search_sv(tss, scaler, LinearSVR(), param_grid_linear, 'SVR/LSVR/params/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time period:1, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:50964': 2, 'tcp://127.0.0.1:50965': 2, 'tcp://127.0.0.1:50968': 2, 'tcp://127.0.0.1:50971': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.08099509874979655 minuts\n",
      "time period:1, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:51027': 2, 'tcp://127.0.0.1:51036': 2, 'tcp://127.0.0.1:51037': 2, 'tcp://127.0.0.1:51038': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.25371012290318806 minuts\n",
      "time period:1, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:51098': 2, 'tcp://127.0.0.1:51100': 2, 'tcp://127.0.0.1:51102': 2, 'tcp://127.0.0.1:51104': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 6.915591748555501 minuts\n",
      "time period:2, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:51181': 2, 'tcp://127.0.0.1:51192': 2, 'tcp://127.0.0.1:51194': 2, 'tcp://127.0.0.1:51198': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.07763895988464356 minuts\n",
      "time period:2, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:51255': 2, 'tcp://127.0.0.1:51260': 2, 'tcp://127.0.0.1:51263': 2, 'tcp://127.0.0.1:51264': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.14341527620951336 minuts\n",
      "time period:2, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:51321': 2, 'tcp://127.0.0.1:51324': 2, 'tcp://127.0.0.1:51325': 2, 'tcp://127.0.0.1:51328': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 3.0345326622327167 minuts\n",
      "time period:6, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:51388': 2, 'tcp://127.0.0.1:51397': 2, 'tcp://127.0.0.1:51400': 2, 'tcp://127.0.0.1:51401': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.06938527822494507 minuts\n",
      "time period:6, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:51458': 2, 'tcp://127.0.0.1:51467': 2, 'tcp://127.0.0.1:51472': 2, 'tcp://127.0.0.1:51473': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.08304099639256796 minuts\n",
      "time period:6, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:51522': 2, 'tcp://127.0.0.1:51528': 2, 'tcp://127.0.0.1:51536': 2, 'tcp://127.0.0.1:51539': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.908526357014974 minuts\n",
      "time period:24, resolution:h3_res_4\n",
      "Number of cores: {'tcp://127.0.0.1:51599': 2, 'tcp://127.0.0.1:51602': 2, 'tcp://127.0.0.1:51603': 2, 'tcp://127.0.0.1:51608': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.07732817729314169 minuts\n",
      "time period:24, resolution:h3_res_6\n",
      "Number of cores: {'tcp://127.0.0.1:51657': 2, 'tcp://127.0.0.1:51672': 2, 'tcp://127.0.0.1:51673': 2, 'tcp://127.0.0.1:51675': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.07644121646881104 minuts\n",
      "time period:24, resolution:h3_res_8\n",
      "Number of cores: {'tcp://127.0.0.1:51731': 2, 'tcp://127.0.0.1:51734': 2, 'tcp://127.0.0.1:51745': 2, 'tcp://127.0.0.1:51746': 2}\n",
      "Dashboard link: http://127.0.0.1:8787/status\n",
      "GridSearch took: 0.1998263955116272 minuts\n"
     ]
    }
   ],
   "source": [
    "grid_search_sv(tss, scaler, SVR(), param_grid_linear, 'SVR/KSVR/params/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models with different time/spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__model__C': 1, 'regressor__model__epsilon': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Load the best models and params from the gridsearch and safe them in a dictionary\n",
    "params_lsvr={}\n",
    "for period in time_periods:\n",
    "    dictionary = {}\n",
    "    for res in resolution:\n",
    "        dictionary[res] = joblib.load(f'Models\\SVR\\lsvr_{period}_{res}')\n",
    "    params_lsvr[period] = dictionary\n",
    "\n",
    "print(params_lsvr.get(1).get('h3_res_4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Split k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Window Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start End Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "timeperiod:1, resolution:h3_res_4\n",
      "R-squared 0.9999871226443094\n",
      "Mean Squared Error 0.0027424234165094948\n",
      "\n",
      "timeperiod:1, resolution:h3_res_6\n",
      "R-squared 0.9999952378325307\n",
      "Mean Squared Error 0.0017332347287190523\n",
      "\n",
      "timeperiod:1, resolution:h3_res_8\n",
      "R-squared 0.9999959570591351\n",
      "Mean Squared Error 0.0017129168077695816\n",
      "\n",
      "timeperiod:2, resolution:h3_res_4\n",
      "R-squared 0.999982988926642\n",
      "Mean Squared Error 0.0030901740194749765\n",
      "\n",
      "timeperiod:2, resolution:h3_res_6\n",
      "R-squared 0.9999948517879766\n",
      "Mean Squared Error 0.0017424911679000813\n",
      "\n",
      "timeperiod:2, resolution:h3_res_8\n",
      "R-squared 0.9999878228349314\n",
      "Mean Squared Error 0.003069825955569509\n",
      "\n",
      "timeperiod:6, resolution:h3_res_4\n",
      "R-squared 0.9999700440909678\n",
      "Mean Squared Error 0.004028659808718887\n",
      "\n",
      "timeperiod:6, resolution:h3_res_6\n",
      "R-squared 0.9999864207017595\n",
      "Mean Squared Error 0.0028976242091743806\n",
      "\n",
      "timeperiod:6, resolution:h3_res_8\n",
      "R-squared 0.9999795553073947\n",
      "Mean Squared Error 0.0040006561372068\n",
      "\n",
      "timeperiod:24, resolution:h3_res_4\n",
      "R-squared 0.9999513351255536\n",
      "Mean Squared Error 0.005000053782543893\n",
      "\n",
      "timeperiod:24, resolution:h3_res_6\n",
      "R-squared 0.9999908346457065\n",
      "Mean Squared Error 0.0019116609765232032\n",
      "\n",
      "timeperiod:24, resolution:h3_res_8\n",
      "R-squared 0.9999931725214001\n",
      "Mean Squared Error 0.002081565890500822\n"
     ]
    }
   ],
   "source": [
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        print(f'\\ntimeperiod: {period}, resolution: {res}')\n",
    "        \n",
    "        df = prediction_data.get(period).get(res)\n",
    "        columns = get_columns(df, \"cos\")\n",
    "        model = LinearSVR()\n",
    "        params= params_lsvr.get(period).get(res)\n",
    "        \n",
    "        sorted_train_test_split(df[columns], df[['number_of_trips']], 0.15, model, train_lsvr, params=params)\n",
    "        \n",
    "        joblib.dump(model, f'Models/SVR/LSVR/models/lsvr_{period}_{res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compare the results of the different time/spaitla bin combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyize the models with XAI methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(12, input_shape=(13,), activation='relu'))\n",
    "nn_model.add(Dense(8, activation='relu'))\n",
    "nn_model.add(Dense(4, activation='relu'))\n",
    "nn_model.add(Dense(1))\n",
    "nn_model.save_weights('initial_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"optimizer\":\"RMSPROP\",\n",
    "    \"loss\":\"mse\",\n",
    "    \"loss_weights\":None,\n",
    "    \"metrics\":['mae'],\n",
    "    \"weighted_metrics\":None,\n",
    "    \"run_eagerly\":False,\n",
    "    #\"steps_per_execution\":1,\n",
    "    \"jit_compile\":\"auto\",\n",
    "    \"auto_scale_loss\":True,\n",
    "    \"x\":None,\n",
    "    \"y\":None,\n",
    "    \"batch_size\":50,\n",
    "    \"epochs\":200,\n",
    "    \"verbose\":1,\n",
    "    \"callbacks\":None,\n",
    "    \"validation_split\":0.0,\n",
    "    \"validation_data\":None,\n",
    "    \"shuffle\":True,\n",
    "    \"class_weight\":None,\n",
    "    \"sample_weight\":None,\n",
    "    \"initial_epoch\":0,\n",
    "    \"steps_per_epoch\":None,\n",
    "    \"validation_steps\":None,\n",
    "    #\"validation_batch_size\":None,\n",
    "    \"validation_freq\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models with different time/spatial bins and different test/train spilt techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Split k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.load_weights('initial_weights')\n",
    "batch_split_cross_validation(3, 24, df[features], df[['number_of_trips']], nn_model, train_nn, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Window Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start End Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h3_res_4 1\n",
      "temperature                 0\n",
      "precipitation               0\n",
      "number_of_trips             0\n",
      "hour_sin                    0\n",
      "hour_cos                    0\n",
      "weekday_sin                 0\n",
      "weekday_cos                 0\n",
      "lagged_1h                   0\n",
      "lagged_1day                 0\n",
      "h3_res_4_8426641ffffffff    0\n",
      "h3_res_4_8426645ffffffff    0\n",
      "h3_res_4_842664dffffffff    0\n",
      "h3_res_4_8427593ffffffff    0\n",
      "dtype: int64\n",
      "Epoch 1/200\n",
      "1238/1238 [==============================] - 0s 160us/sample - loss: 1.0285 - mean_absolute_error: 0.7334\n",
      "Epoch 2/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.9335 - mean_absolute_error: 0.6914\n",
      "Epoch 3/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.8796 - mean_absolute_error: 0.6424\n",
      "Epoch 4/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.8288 - mean_absolute_error: 0.5901\n",
      "Epoch 5/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.7823 - mean_absolute_error: 0.5378\n",
      "Epoch 6/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.7486 - mean_absolute_error: 0.5024\n",
      "Epoch 7/200\n",
      "1238/1238 [==============================] - 0s 27us/sample - loss: 0.7236 - mean_absolute_error: 0.4791\n",
      "Epoch 8/200\n",
      "1238/1238 [==============================] - 0s 25us/sample - loss: 0.7030 - mean_absolute_error: 0.4625\n",
      "Epoch 9/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.6852 - mean_absolute_error: 0.4492\n",
      "Epoch 10/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.6689 - mean_absolute_error: 0.4373\n",
      "Epoch 11/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.6535 - mean_absolute_error: 0.4271\n",
      "Epoch 12/200\n",
      "1238/1238 [==============================] - 0s 25us/sample - loss: 0.6386 - mean_absolute_error: 0.4175\n",
      "Epoch 13/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.6247 - mean_absolute_error: 0.4104\n",
      "Epoch 14/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.6121 - mean_absolute_error: 0.4038\n",
      "Epoch 15/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.5994 - mean_absolute_error: 0.3980\n",
      "Epoch 16/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.5879 - mean_absolute_error: 0.3930\n",
      "Epoch 17/200\n",
      "1238/1238 [==============================] - 0s 40us/sample - loss: 0.5767 - mean_absolute_error: 0.3889\n",
      "Epoch 18/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.5658 - mean_absolute_error: 0.3855\n",
      "Epoch 19/200\n",
      "1238/1238 [==============================] - 0s 44us/sample - loss: 0.5554 - mean_absolute_error: 0.3813\n",
      "Epoch 20/200\n",
      "1238/1238 [==============================] - 0s 52us/sample - loss: 0.5454 - mean_absolute_error: 0.3782\n",
      "Epoch 21/200\n",
      "1238/1238 [==============================] - 0s 56us/sample - loss: 0.5358 - mean_absolute_error: 0.3743\n",
      "Epoch 22/200\n",
      "1238/1238 [==============================] - 0s 38us/sample - loss: 0.5269 - mean_absolute_error: 0.3715\n",
      "Epoch 23/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.5181 - mean_absolute_error: 0.3684\n",
      "Epoch 24/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.5101 - mean_absolute_error: 0.3657\n",
      "Epoch 25/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.5020 - mean_absolute_error: 0.3627\n",
      "Epoch 26/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.4945 - mean_absolute_error: 0.3598\n",
      "Epoch 27/200\n",
      "1238/1238 [==============================] - 0s 23us/sample - loss: 0.4877 - mean_absolute_error: 0.3574\n",
      "Epoch 28/200\n",
      "1238/1238 [==============================] - 0s 38us/sample - loss: 0.4812 - mean_absolute_error: 0.3545\n",
      "Epoch 29/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.4754 - mean_absolute_error: 0.3520\n",
      "Epoch 30/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.4697 - mean_absolute_error: 0.3494\n",
      "Epoch 31/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.4639 - mean_absolute_error: 0.3473\n",
      "Epoch 32/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.4590 - mean_absolute_error: 0.3463\n",
      "Epoch 33/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.4540 - mean_absolute_error: 0.3439\n",
      "Epoch 34/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.4494 - mean_absolute_error: 0.3425\n",
      "Epoch 35/200\n",
      "1238/1238 [==============================] - 0s 23us/sample - loss: 0.4451 - mean_absolute_error: 0.3413\n",
      "Epoch 36/200\n",
      "1238/1238 [==============================] - 0s 18us/sample - loss: 0.4415 - mean_absolute_error: 0.3398\n",
      "Epoch 37/200\n",
      "1238/1238 [==============================] - 0s 27us/sample - loss: 0.4382 - mean_absolute_error: 0.3388\n",
      "Epoch 38/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.4352 - mean_absolute_error: 0.3381\n",
      "Epoch 39/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.4321 - mean_absolute_error: 0.3368\n",
      "Epoch 40/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.4297 - mean_absolute_error: 0.3366\n",
      "Epoch 41/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.4276 - mean_absolute_error: 0.3355\n",
      "Epoch 42/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.4255 - mean_absolute_error: 0.3353\n",
      "Epoch 43/200\n",
      "1238/1238 [==============================] - 0s 24us/sample - loss: 0.4218 - mean_absolute_error: 0.3344\n",
      "Epoch 44/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.3689 - mean_absolute_error: 0.3194\n",
      "Epoch 45/200\n",
      "1238/1238 [==============================] - 0s 38us/sample - loss: 0.3127 - mean_absolute_error: 0.2815\n",
      "Epoch 46/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.2842 - mean_absolute_error: 0.2507\n",
      "Epoch 47/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.2677 - mean_absolute_error: 0.2300\n",
      "Epoch 48/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.2562 - mean_absolute_error: 0.2183\n",
      "Epoch 49/200\n",
      "1238/1238 [==============================] - 0s 25us/sample - loss: 0.2468 - mean_absolute_error: 0.2083\n",
      "Epoch 50/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.2380 - mean_absolute_error: 0.2005\n",
      "Epoch 51/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.2296 - mean_absolute_error: 0.1935\n",
      "Epoch 52/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.2212 - mean_absolute_error: 0.1861\n",
      "Epoch 53/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.2135 - mean_absolute_error: 0.1813\n",
      "Epoch 54/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.2060 - mean_absolute_error: 0.1759\n",
      "Epoch 55/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.1993 - mean_absolute_error: 0.1708\n",
      "Epoch 56/200\n",
      "1238/1238 [==============================] - 0s 27us/sample - loss: 0.1923 - mean_absolute_error: 0.1664\n",
      "Epoch 57/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.1855 - mean_absolute_error: 0.1619\n",
      "Epoch 58/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.1793 - mean_absolute_error: 0.1574\n",
      "Epoch 59/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.1730 - mean_absolute_error: 0.1537\n",
      "Epoch 60/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.1673 - mean_absolute_error: 0.1495\n",
      "Epoch 61/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.1615 - mean_absolute_error: 0.1460\n",
      "Epoch 62/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.1557 - mean_absolute_error: 0.1421\n",
      "Epoch 63/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.1502 - mean_absolute_error: 0.1391\n",
      "Epoch 64/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.1446 - mean_absolute_error: 0.1347\n",
      "Epoch 65/200\n",
      "1238/1238 [==============================] - 0s 42us/sample - loss: 0.1396 - mean_absolute_error: 0.1315\n",
      "Epoch 66/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.1343 - mean_absolute_error: 0.1286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "1238/1238 [==============================] - 0s 44us/sample - loss: 0.1291 - mean_absolute_error: 0.1251\n",
      "Epoch 68/200\n",
      "1238/1238 [==============================] - 0s 43us/sample - loss: 0.1245 - mean_absolute_error: 0.1217\n",
      "Epoch 69/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.1198 - mean_absolute_error: 0.1191\n",
      "Epoch 70/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.1150 - mean_absolute_error: 0.1156\n",
      "Epoch 71/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.1104 - mean_absolute_error: 0.1133\n",
      "Epoch 72/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.1062 - mean_absolute_error: 0.1108\n",
      "Epoch 73/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.1020 - mean_absolute_error: 0.1076\n",
      "Epoch 74/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0979 - mean_absolute_error: 0.1050\n",
      "Epoch 75/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.0940 - mean_absolute_error: 0.1023\n",
      "Epoch 76/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.0902 - mean_absolute_error: 0.1003\n",
      "Epoch 77/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0866 - mean_absolute_error: 0.0969\n",
      "Epoch 78/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0832 - mean_absolute_error: 0.0955\n",
      "Epoch 79/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0797 - mean_absolute_error: 0.0919\n",
      "Epoch 80/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0765 - mean_absolute_error: 0.0908\n",
      "Epoch 81/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0733 - mean_absolute_error: 0.0883\n",
      "Epoch 82/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.0701 - mean_absolute_error: 0.0849\n",
      "Epoch 83/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0672 - mean_absolute_error: 0.0839\n",
      "Epoch 84/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0642 - mean_absolute_error: 0.0800\n",
      "Epoch 85/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0615 - mean_absolute_error: 0.0792\n",
      "Epoch 86/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0589 - mean_absolute_error: 0.0770\n",
      "Epoch 87/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.0563 - mean_absolute_error: 0.0754\n",
      "Epoch 88/200\n",
      "1238/1238 [==============================] - 0s 38us/sample - loss: 0.0539 - mean_absolute_error: 0.0735\n",
      "Epoch 89/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.0514 - mean_absolute_error: 0.0710\n",
      "Epoch 90/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0491 - mean_absolute_error: 0.0687\n",
      "Epoch 91/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0470 - mean_absolute_error: 0.0676\n",
      "Epoch 92/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.0448 - mean_absolute_error: 0.0648\n",
      "Epoch 93/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0427 - mean_absolute_error: 0.0635\n",
      "Epoch 94/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0406 - mean_absolute_error: 0.0622\n",
      "Epoch 95/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.0389 - mean_absolute_error: 0.0608\n",
      "Epoch 96/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0370 - mean_absolute_error: 0.0583\n",
      "Epoch 97/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0354 - mean_absolute_error: 0.0582\n",
      "Epoch 98/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0336 - mean_absolute_error: 0.0549\n",
      "Epoch 99/200\n",
      "1238/1238 [==============================] - 0s 41us/sample - loss: 0.0321 - mean_absolute_error: 0.0549\n",
      "Epoch 100/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0305 - mean_absolute_error: 0.0522\n",
      "Epoch 101/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0291 - mean_absolute_error: 0.0516\n",
      "Epoch 102/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.0278 - mean_absolute_error: 0.0508\n",
      "Epoch 103/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0264 - mean_absolute_error: 0.0483\n",
      "Epoch 104/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0253 - mean_absolute_error: 0.0489\n",
      "Epoch 105/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0240 - mean_absolute_error: 0.0463\n",
      "Epoch 106/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_absolute_error: 0.0459\n",
      "Epoch 107/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0216 - mean_absolute_error: 0.0444\n",
      "Epoch 108/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0206 - mean_absolute_error: 0.0440\n",
      "Epoch 109/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0196 - mean_absolute_error: 0.0416\n",
      "Epoch 110/200\n",
      "1238/1238 [==============================] - 0s 41us/sample - loss: 0.0187 - mean_absolute_error: 0.0425\n",
      "Epoch 111/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0179 - mean_absolute_error: 0.0417\n",
      "Epoch 112/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0171 - mean_absolute_error: 0.0394\n",
      "Epoch 113/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0162 - mean_absolute_error: 0.0383\n",
      "Epoch 114/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0156 - mean_absolute_error: 0.0385\n",
      "Epoch 115/200\n",
      "1238/1238 [==============================] - 0s 27us/sample - loss: 0.0149 - mean_absolute_error: 0.0376\n",
      "Epoch 116/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.0141 - mean_absolute_error: 0.0360\n",
      "Epoch 117/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0135 - mean_absolute_error: 0.0363\n",
      "Epoch 118/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.0129 - mean_absolute_error: 0.0360\n",
      "Epoch 119/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0123 - mean_absolute_error: 0.0340\n",
      "Epoch 120/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0118 - mean_absolute_error: 0.0346\n",
      "Epoch 121/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0113 - mean_absolute_error: 0.0327\n",
      "Epoch 122/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0108 - mean_absolute_error: 0.0317\n",
      "Epoch 123/200\n",
      "1238/1238 [==============================] - 0s 40us/sample - loss: 0.0103 - mean_absolute_error: 0.0324\n",
      "Epoch 124/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0098 - mean_absolute_error: 0.0311\n",
      "Epoch 125/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0094 - mean_absolute_error: 0.0319\n",
      "Epoch 126/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0089 - mean_absolute_error: 0.0285\n",
      "Epoch 127/200\n",
      "1238/1238 [==============================] - 0s 21us/sample - loss: 0.0087 - mean_absolute_error: 0.0306\n",
      "Epoch 128/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0082 - mean_absolute_error: 0.0291\n",
      "Epoch 129/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.0080 - mean_absolute_error: 0.0301\n",
      "Epoch 130/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.0077 - mean_absolute_error: 0.0279\n",
      "Epoch 131/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0074 - mean_absolute_error: 0.0279\n",
      "Epoch 132/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0072 - mean_absolute_error: 0.0281\n",
      "Epoch 133/200\n",
      "1238/1238 [==============================] - 0s 27us/sample - loss: 0.0070 - mean_absolute_error: 0.0281\n",
      "Epoch 134/200\n",
      "1238/1238 [==============================] - 0s 49us/sample - loss: 0.0067 - mean_absolute_error: 0.0276\n",
      "Epoch 135/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0064 - mean_absolute_error: 0.0257\n",
      "Epoch 136/200\n",
      "1238/1238 [==============================] - 0s 23us/sample - loss: 0.0062 - mean_absolute_error: 0.0267\n",
      "Epoch 137/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0060 - mean_absolute_error: 0.0255\n",
      "Epoch 138/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0058 - mean_absolute_error: 0.0263\n",
      "Epoch 139/200\n",
      "1238/1238 [==============================] - 0s 24us/sample - loss: 0.0057 - mean_absolute_error: 0.0259\n",
      "Epoch 140/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0054 - mean_absolute_error: 0.0257\n",
      "Epoch 141/200\n",
      "1238/1238 [==============================] - 0s 21us/sample - loss: 0.0053 - mean_absolute_error: 0.0266\n",
      "Epoch 142/200\n",
      "1238/1238 [==============================] - 0s 27us/sample - loss: 0.0051 - mean_absolute_error: 0.0245\n",
      "Epoch 143/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0050 - mean_absolute_error: 0.0259\n",
      "Epoch 144/200\n",
      "1238/1238 [==============================] - 0s 24us/sample - loss: 0.0048 - mean_absolute_error: 0.0247\n",
      "Epoch 145/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.0047 - mean_absolute_error: 0.0252\n",
      "Epoch 146/200\n",
      "1238/1238 [==============================] - 0s 24us/sample - loss: 0.0046 - mean_absolute_error: 0.0250\n",
      "Epoch 147/200\n",
      "1238/1238 [==============================] - 0s 25us/sample - loss: 0.0044 - mean_absolute_error: 0.0238\n",
      "Epoch 148/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0043 - mean_absolute_error: 0.0246\n",
      "Epoch 149/200\n",
      "1238/1238 [==============================] - 0s 18us/sample - loss: 0.0041 - mean_absolute_error: 0.0229\n",
      "Epoch 150/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.0041 - mean_absolute_error: 0.0235\n",
      "Epoch 151/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0040 - mean_absolute_error: 0.0248\n",
      "Epoch 152/200\n",
      "1238/1238 [==============================] - 0s 25us/sample - loss: 0.0039 - mean_absolute_error: 0.0233\n",
      "Epoch 153/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0038 - mean_absolute_error: 0.0235\n",
      "Epoch 154/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0037 - mean_absolute_error: 0.0235\n",
      "Epoch 155/200\n",
      "1238/1238 [==============================] - 0s 24us/sample - loss: 0.0036 - mean_absolute_error: 0.0235\n",
      "Epoch 156/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0035 - mean_absolute_error: 0.0235\n",
      "Epoch 157/200\n",
      "1238/1238 [==============================] - 0s 24us/sample - loss: 0.0035 - mean_absolute_error: 0.0233\n",
      "Epoch 158/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.0034 - mean_absolute_error: 0.0230\n",
      "Epoch 159/200\n",
      "1238/1238 [==============================] - 0s 28us/sample - loss: 0.0034 - mean_absolute_error: 0.0247\n",
      "Epoch 160/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0031 - mean_absolute_error: 0.0201\n",
      "Epoch 161/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.0032 - mean_absolute_error: 0.0228\n",
      "Epoch 162/200\n",
      "1238/1238 [==============================] - 0s 39us/sample - loss: 0.0031 - mean_absolute_error: 0.0235\n",
      "Epoch 163/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0030 - mean_absolute_error: 0.0224\n",
      "Epoch 164/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0030 - mean_absolute_error: 0.0222\n",
      "Epoch 165/200\n",
      "1238/1238 [==============================] - 0s 23us/sample - loss: 0.0030 - mean_absolute_error: 0.0235\n",
      "Epoch 166/200\n",
      "1238/1238 [==============================] - 0s 25us/sample - loss: 0.0028 - mean_absolute_error: 0.0216\n",
      "Epoch 167/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0028 - mean_absolute_error: 0.0202\n",
      "Epoch 168/200\n",
      "1238/1238 [==============================] - 0s 37us/sample - loss: 0.0027 - mean_absolute_error: 0.0204\n",
      "Epoch 169/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0027 - mean_absolute_error: 0.0223\n",
      "Epoch 170/200\n",
      "1238/1238 [==============================] - 0s 36us/sample - loss: 0.0026 - mean_absolute_error: 0.0217\n",
      "Epoch 171/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0026 - mean_absolute_error: 0.0221\n",
      "Epoch 172/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0025 - mean_absolute_error: 0.0198\n",
      "Epoch 173/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.0025 - mean_absolute_error: 0.0230\n",
      "Epoch 174/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0024 - mean_absolute_error: 0.0194\n",
      "Epoch 175/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0025 - mean_absolute_error: 0.0227\n",
      "Epoch 176/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0024 - mean_absolute_error: 0.0221\n",
      "Epoch 177/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0023 - mean_absolute_error: 0.0216\n",
      "Epoch 178/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0022 - mean_absolute_error: 0.0208\n",
      "Epoch 179/200\n",
      "1238/1238 [==============================] - 0s 33us/sample - loss: 0.0022 - mean_absolute_error: 0.0225\n",
      "Epoch 180/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0022 - mean_absolute_error: 0.0189\n",
      "Epoch 181/200\n",
      "1238/1238 [==============================] - 0s 26us/sample - loss: 0.0022 - mean_absolute_error: 0.0212\n",
      "Epoch 182/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0021 - mean_absolute_error: 0.0202\n",
      "Epoch 183/200\n",
      "1238/1238 [==============================] - 0s 38us/sample - loss: 0.0022 - mean_absolute_error: 0.0217\n",
      "Epoch 184/200\n",
      "1238/1238 [==============================] - 0s 38us/sample - loss: 0.0021 - mean_absolute_error: 0.0216\n",
      "Epoch 185/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.0020 - mean_absolute_error: 0.0198\n",
      "Epoch 186/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0020 - mean_absolute_error: 0.0204\n",
      "Epoch 187/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0020 - mean_absolute_error: 0.0221\n",
      "Epoch 188/200\n",
      "1238/1238 [==============================] - 0s 23us/sample - loss: 0.0020 - mean_absolute_error: 0.0201\n",
      "Epoch 189/200\n",
      "1238/1238 [==============================] - 0s 31us/sample - loss: 0.0019 - mean_absolute_error: 0.0195\n",
      "Epoch 190/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0019 - mean_absolute_error: 0.0208\n",
      "Epoch 191/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0205\n",
      "Epoch 192/200\n",
      "1238/1238 [==============================] - 0s 34us/sample - loss: 0.0019 - mean_absolute_error: 0.0213\n",
      "Epoch 193/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0018 - mean_absolute_error: 0.0211\n",
      "Epoch 194/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0018 - mean_absolute_error: 0.0208\n",
      "Epoch 195/200\n",
      "1238/1238 [==============================] - 0s 46us/sample - loss: 0.0018 - mean_absolute_error: 0.0204\n",
      "Epoch 196/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0018 - mean_absolute_error: 0.0213\n",
      "Epoch 197/200\n",
      "1238/1238 [==============================] - 0s 30us/sample - loss: 0.0017 - mean_absolute_error: 0.0202\n",
      "Epoch 198/200\n",
      "1238/1238 [==============================] - 0s 35us/sample - loss: 0.0017 - mean_absolute_error: 0.0196\n",
      "Epoch 199/200\n",
      "1238/1238 [==============================] - 0s 29us/sample - loss: 0.0017 - mean_absolute_error: 0.0207\n",
      "Epoch 200/200\n",
      "1238/1238 [==============================] - 0s 32us/sample - loss: 0.0017 - mean_absolute_error: 0.0204\n",
      "R-squared 0.9981467139350374\n",
      "Mean Squared Error 0.039455720232257484\n",
      "h3_res_6 1\n",
      "temperature                 0\n",
      "precipitation               0\n",
      "number_of_trips             0\n",
      "hour_sin                    0\n",
      "hour_cos                    0\n",
      "weekday_sin                 0\n",
      "weekday_cos                 0\n",
      "lagged_1h                   0\n",
      "lagged_1day                 0\n",
      "h3_res_6_862664197ffffff    0\n",
      "h3_res_6_8626641b7ffffff    0\n",
      "h3_res_6_862664527ffffff    0\n",
      "h3_res_6_86266452fffffff    0\n",
      "h3_res_6_862664567ffffff    0\n",
      "h3_res_6_86266456fffffff    0\n",
      "h3_res_6_862664577ffffff    0\n",
      "h3_res_6_862664c17ffffff    0\n",
      "h3_res_6_862664c1fffffff    0\n",
      "h3_res_6_862664c87ffffff    0\n",
      "h3_res_6_862664c8fffffff    0\n",
      "h3_res_6_862664ca7ffffff    0\n",
      "h3_res_6_862664cafffffff    0\n",
      "h3_res_6_862664cb7ffffff    0\n",
      "h3_res_6_862664cc7ffffff    0\n",
      "h3_res_6_862664ccfffffff    0\n",
      "h3_res_6_862664cd7ffffff    0\n",
      "h3_res_6_862664cdfffffff    0\n",
      "h3_res_6_862664ce7ffffff    0\n",
      "h3_res_6_862664cefffffff    0\n",
      "h3_res_6_862664cf7ffffff    0\n",
      "h3_res_6_862664d87ffffff    0\n",
      "h3_res_6_862664d8fffffff    0\n",
      "h3_res_6_862664d9fffffff    0\n",
      "h3_res_6_862759347ffffff    0\n",
      "h3_res_6_86275934fffffff    0\n",
      "h3_res_6_86275936fffffff    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7256/7256 [==============================] - 0s 44us/sample - loss: 1.0172 - mean_absolute_error: 0.4059\n",
      "Epoch 2/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.9988 - mean_absolute_error: 0.3898\n",
      "Epoch 3/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.6352 - mean_absolute_error: 0.3285\n",
      "Epoch 4/200\n",
      "7256/7256 [==============================] - 0s 23us/sample - loss: 0.0254 - mean_absolute_error: 0.1281\n",
      "Epoch 5/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0076 - mean_absolute_error: 0.0600\n",
      "Epoch 6/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0057 - mean_absolute_error: 0.0495\n",
      "Epoch 7/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0045 - mean_absolute_error: 0.0421\n",
      "Epoch 8/200\n",
      "7256/7256 [==============================] - 0s 23us/sample - loss: 0.0028 - mean_absolute_error: 0.0289\n",
      "Epoch 9/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 0.0026 - mean_absolute_error: 0.0265\n",
      "Epoch 10/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 0.0021 - mean_absolute_error: 0.0236\n",
      "Epoch 11/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0021 - mean_absolute_error: 0.0230\n",
      "Epoch 12/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 0.0021 - mean_absolute_error: 0.0220\n",
      "Epoch 13/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 0.0019 - mean_absolute_error: 0.0217\n",
      "Epoch 14/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0016 - mean_absolute_error: 0.0205\n",
      "Epoch 15/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0019 - mean_absolute_error: 0.0215\n",
      "Epoch 16/200\n",
      "7256/7256 [==============================] - 0s 20us/sample - loss: 0.0014 - mean_absolute_error: 0.0191\n",
      "Epoch 17/200\n",
      "7256/7256 [==============================] - 0s 20us/sample - loss: 0.0015 - mean_absolute_error: 0.0197\n",
      "Epoch 18/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 0.0016 - mean_absolute_error: 0.0180\n",
      "Epoch 19/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 0.0014 - mean_absolute_error: 0.0180\n",
      "Epoch 20/200\n",
      "7256/7256 [==============================] - 0s 33us/sample - loss: 0.0015 - mean_absolute_error: 0.0179\n",
      "Epoch 21/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0013 - mean_absolute_error: 0.0181\n",
      "Epoch 22/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0012 - mean_absolute_error: 0.0171\n",
      "Epoch 23/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0014 - mean_absolute_error: 0.0173\n",
      "Epoch 24/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0012 - mean_absolute_error: 0.0170\n",
      "Epoch 25/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0013 - mean_absolute_error: 0.0171\n",
      "Epoch 26/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0012 - mean_absolute_error: 0.0161\n",
      "Epoch 27/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0012 - mean_absolute_error: 0.0159\n",
      "Epoch 28/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0011 - mean_absolute_error: 0.0155\n",
      "Epoch 29/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0011 - mean_absolute_error: 0.0155\n",
      "Epoch 30/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 0.0010 - mean_absolute_error: 0.0153\n",
      "Epoch 31/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 0.0011 - mean_absolute_error: 0.0145\n",
      "Epoch 32/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 9.2865e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 33/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 0.0012 - mean_absolute_error: 0.0150\n",
      "Epoch 34/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 9.9696e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 35/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 8.9546e-04 - mean_absolute_error: 0.0135\n",
      "Epoch 36/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 9.2487e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 37/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 8.3119e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 38/200\n",
      "7256/7256 [==============================] - 0s 23us/sample - loss: 9.5140e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 39/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 7.7377e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 40/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 8.3182e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 41/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 7.8193e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 42/200\n",
      "7256/7256 [==============================] - 0s 22us/sample - loss: 7.5659e-04 - mean_absolute_error: 0.0128\n",
      "Epoch 43/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 7.0451e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 44/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 9.2262e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 45/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 6.5423e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 46/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 7.5299e-04 - mean_absolute_error: 0.0124\n",
      "Epoch 47/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 6.4289e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 48/200\n",
      "7256/7256 [==============================] - 0s 34us/sample - loss: 6.3438e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 49/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 7.3285e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 50/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 6.8653e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 51/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 6.2656e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 52/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 6.6846e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 53/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 6.4824e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 54/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 6.7186e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 55/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 5.7916e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 56/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 6.0257e-04 - mean_absolute_error: 0.0118\n",
      "Epoch 57/200\n",
      "7256/7256 [==============================] - 0s 45us/sample - loss: 5.9856e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 58/200\n",
      "7256/7256 [==============================] - 0s 39us/sample - loss: 6.7713e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 59/200\n",
      "7256/7256 [==============================] - 0s 49us/sample - loss: 5.6373e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 60/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 5.9579e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 61/200\n",
      "7256/7256 [==============================] - 0s 40us/sample - loss: 5.9282e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 62/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 5.9251e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 63/200\n",
      "7256/7256 [==============================] - 0s 41us/sample - loss: 5.4146e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 64/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 5.9456e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 65/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 4.9827e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 66/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 5.6894e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 67/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 5.1229e-04 - mean_absolute_error: 0.0108\n",
      "Epoch 68/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 5.7177e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 69/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 5.0101e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 70/200\n",
      "7256/7256 [==============================] - 0s 41us/sample - loss: 5.5265e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 71/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 5.2562e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 72/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 5.2355e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 73/200\n",
      "7256/7256 [==============================] - 0s 35us/sample - loss: 5.4726e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 74/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 5.2829e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 75/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 4.4702e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 76/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 5.4638e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 77/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 4.7619e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 78/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 4.9272e-04 - mean_absolute_error: 0.0103\n",
      "Epoch 79/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 4.6928e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 80/200\n",
      "7256/7256 [==============================] - 0s 34us/sample - loss: 4.3451e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 81/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 5.4845e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 82/200\n",
      "7256/7256 [==============================] - 0s 39us/sample - loss: 4.3757e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 83/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 4.4318e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 84/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 4.8229e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 85/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 4.3685e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 86/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 4.2808e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 87/200\n",
      "7256/7256 [==============================] - 0s 35us/sample - loss: 3.9834e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 88/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 4.3750e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 89/200\n",
      "7256/7256 [==============================] - 0s 45us/sample - loss: 4.6078e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 90/200\n",
      "7256/7256 [==============================] - 0s 34us/sample - loss: 4.0782e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 91/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 4.4966e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 92/200\n",
      "7256/7256 [==============================] - 0s 41us/sample - loss: 4.5707e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 93/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 4.9621e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 94/200\n",
      "7256/7256 [==============================] - 0s 41us/sample - loss: 4.6739e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 95/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 4.3339e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 96/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 4.1171e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 97/200\n",
      "7256/7256 [==============================] - 0s 33us/sample - loss: 4.0239e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 98/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 4.1493e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 99/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 4.1438e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 100/200\n",
      "7256/7256 [==============================] - 0s 35us/sample - loss: 4.2236e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 101/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 3.9238e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 102/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 4.2791e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 103/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 3.5212e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 104/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 4.4790e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 105/200\n",
      "7256/7256 [==============================] - 0s 44us/sample - loss: 4.2682e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 106/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 4.1760e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 107/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 3.5840e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 108/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 3.9013e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 109/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 4.4365e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 110/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 3.4418e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 111/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 3.6789e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 112/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 4.0099e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 113/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 4.0663e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 114/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 3.3306e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 115/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 3.6928e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 116/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 3.8900e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 117/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 3.5382e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 118/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 4.3632e-04 - mean_absolute_error: 0.0089\n",
      "Epoch 119/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 3.7769e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 120/200\n",
      "7256/7256 [==============================] - 0s 35us/sample - loss: 3.6589e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 121/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 3.6472e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 122/200\n",
      "7256/7256 [==============================] - 0s 46us/sample - loss: 4.0555e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 123/200\n",
      "7256/7256 [==============================] - 0s 34us/sample - loss: 3.4932e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 124/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 3.6973e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 125/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 3.8820e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 126/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 3.3981e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 127/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 4.0192e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 128/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 3.6743e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 129/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 3.2078e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 130/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 3.0282e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 131/200\n",
      "7256/7256 [==============================] - 0s 23us/sample - loss: 3.3495e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 132/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 3.3242e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 133/200\n",
      "7256/7256 [==============================] - 0s 23us/sample - loss: 3.2288e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 134/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 3.3699e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 135/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 3.3170e-04 - mean_absolute_error: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 3.0746e-04 - mean_absolute_error: 0.0079\n",
      "Epoch 137/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.7769e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 138/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 3.0831e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 139/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 3.7781e-04 - mean_absolute_error: 0.0079\n",
      "Epoch 140/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 2.7226e-04 - mean_absolute_error: 0.0076\n",
      "Epoch 141/200\n",
      "7256/7256 [==============================] - 0s 33us/sample - loss: 3.1575e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 142/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 2.9964e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 143/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 3.7366e-04 - mean_absolute_error: 0.0078\n",
      "Epoch 144/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.9694e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 145/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 3.2944e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 146/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 3.0753e-04 - mean_absolute_error: 0.0071\n",
      "Epoch 147/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.9381e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 148/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.9299e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 149/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 3.0406e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 150/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 2.8093e-04 - mean_absolute_error: 0.0073\n",
      "Epoch 151/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 3.2478e-04 - mean_absolute_error: 0.0073\n",
      "Epoch 152/200\n",
      "7256/7256 [==============================] - 0s 21us/sample - loss: 2.5122e-04 - mean_absolute_error: 0.0073\n",
      "Epoch 153/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 2.8656e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 154/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 2.6553e-04 - mean_absolute_error: 0.0073\n",
      "Epoch 155/200\n",
      "7256/7256 [==============================] - 0s 24us/sample - loss: 3.1029e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 156/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.8320e-04 - mean_absolute_error: 0.0073\n",
      "Epoch 157/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.3919e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 158/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.8256e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 159/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.8547e-04 - mean_absolute_error: 0.0071\n",
      "Epoch 160/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 2.6971e-04 - mean_absolute_error: 0.0071\n",
      "Epoch 161/200\n",
      "7256/7256 [==============================] - 0s 34us/sample - loss: 2.7692e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 162/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 2.4117e-04 - mean_absolute_error: 0.0071\n",
      "Epoch 163/200\n",
      "7256/7256 [==============================] - 0s 35us/sample - loss: 2.9864e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 164/200\n",
      "7256/7256 [==============================] - 0s 34us/sample - loss: 2.8051e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 165/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 2.7296e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 166/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 2.7531e-04 - mean_absolute_error: 0.0073\n",
      "Epoch 167/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 2.5172e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 168/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 2.8220e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 169/200\n",
      "7256/7256 [==============================] - 0s 31us/sample - loss: 2.6238e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 170/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.5333e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 171/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 2.7639e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 172/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.5152e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 173/200\n",
      "7256/7256 [==============================] - 0s 26us/sample - loss: 2.7700e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 174/200\n",
      "7256/7256 [==============================] - 0s 25us/sample - loss: 2.2163e-04 - mean_absolute_error: 0.0070\n",
      "Epoch 175/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 2.7374e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 176/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 2.8464e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 177/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 2.3408e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 178/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 2.4457e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 179/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 2.2664e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 180/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 2.6984e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 181/200\n",
      "7256/7256 [==============================] - 0s 45us/sample - loss: 2.6509e-04 - mean_absolute_error: 0.0066\n",
      "Epoch 182/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 2.5705e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 183/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 2.3261e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 184/200\n",
      "7256/7256 [==============================] - 0s 32us/sample - loss: 2.3306e-04 - mean_absolute_error: 0.0070\n",
      "Epoch 185/200\n",
      "7256/7256 [==============================] - 0s 35us/sample - loss: 2.3165e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 186/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 2.5442e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 187/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 2.9747e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 188/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 2.1355e-04 - mean_absolute_error: 0.0062\n",
      "Epoch 189/200\n",
      "7256/7256 [==============================] - 0s 27us/sample - loss: 2.3855e-04 - mean_absolute_error: 0.0066\n",
      "Epoch 190/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 2.6225e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 191/200\n",
      "7256/7256 [==============================] - 0s 41us/sample - loss: 2.0232e-04 - mean_absolute_error: 0.0066\n",
      "Epoch 192/200\n",
      "7256/7256 [==============================] - 0s 29us/sample - loss: 2.7182e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 193/200\n",
      "7256/7256 [==============================] - 0s 33us/sample - loss: 2.4277e-04 - mean_absolute_error: 0.0070\n",
      "Epoch 194/200\n",
      "7256/7256 [==============================] - 0s 30us/sample - loss: 2.4039e-04 - mean_absolute_error: 0.0069\n",
      "Epoch 195/200\n",
      "7256/7256 [==============================] - 0s 42us/sample - loss: 2.3445e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 196/200\n",
      "7256/7256 [==============================] - 0s 38us/sample - loss: 2.3695e-04 - mean_absolute_error: 0.0064\n",
      "Epoch 197/200\n",
      "7256/7256 [==============================] - 0s 37us/sample - loss: 2.2987e-04 - mean_absolute_error: 0.0066\n",
      "Epoch 198/200\n",
      "7256/7256 [==============================] - 0s 41us/sample - loss: 2.2338e-04 - mean_absolute_error: 0.0066\n",
      "Epoch 199/200\n",
      "7256/7256 [==============================] - 0s 36us/sample - loss: 2.3705e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 200/200\n",
      "7256/7256 [==============================] - 0s 28us/sample - loss: 2.3296e-04 - mean_absolute_error: 0.0064\n",
      "R-squared 0.9985540908826777\n",
      "Mean Squared Error 0.01682252579258433\n",
      "h3_res_8 1\n",
      "temperature                 0\n",
      "precipitation               0\n",
      "number_of_trips             0\n",
      "hour_sin                    0\n",
      "hour_cos                    0\n",
      "                           ..\n",
      "h3_res_8_88275934edfffff    0\n",
      "h3_res_8_8827593699fffff    0\n",
      "h3_res_8_88275936b1fffff    0\n",
      "h3_res_8_88275936bbfffff    0\n",
      "h3_res_8_88275936d5fffff    0\n",
      "Length: 250, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26689/26689 [==============================] - 2s 66us/sample - loss: 1.0001 - mean_absolute_error: 0.4526\n",
      "Epoch 2/200\n",
      "26689/26689 [==============================] - 2s 64us/sample - loss: 1.0001 - mean_absolute_error: 0.4470\n",
      "Epoch 3/200\n",
      "26689/26689 [==============================] - 2s 59us/sample - loss: 1.0001 - mean_absolute_error: 0.4512\n",
      "Epoch 4/200\n",
      "26689/26689 [==============================] - 2s 66us/sample - loss: 1.0000 - mean_absolute_error: 0.4513\n",
      "Epoch 5/200\n",
      "26689/26689 [==============================] - 2s 62us/sample - loss: 1.0001 - mean_absolute_error: 0.4460\n",
      "Epoch 6/200\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0001 - mean_absolute_error: 0.4517\n",
      "Epoch 7/200\n",
      "26689/26689 [==============================] - 2s 64us/sample - loss: 1.0001 - mean_absolute_error: 0.4494\n",
      "Epoch 8/200\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0001 - mean_absolute_error: 0.4519\n",
      "Epoch 9/200\n",
      "26689/26689 [==============================] - 2s 65us/sample - loss: 1.0001 - mean_absolute_error: 0.4465\n",
      "Epoch 10/200\n",
      "26689/26689 [==============================] - 2s 59us/sample - loss: 1.0001 - mean_absolute_error: 0.4522\n",
      "Epoch 11/200\n",
      "26689/26689 [==============================] - 2s 68us/sample - loss: 1.0001 - mean_absolute_error: 0.4497\n",
      "Epoch 12/200\n",
      "26689/26689 [==============================] - 2s 61us/sample - loss: 1.0002 - mean_absolute_error: 0.4481\n",
      "Epoch 13/200\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0001 - mean_absolute_error: 0.4503\n",
      "Epoch 14/200\n",
      "26689/26689 [==============================] - 2s 60us/sample - loss: 1.0001 - mean_absolute_error: 0.4500\n",
      "Epoch 15/200\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0002 - mean_absolute_error: 0.4490\n",
      "Epoch 16/200\n",
      "26689/26689 [==============================] - 2s 87us/sample - loss: 1.0001 - mean_absolute_error: 0.4484\n",
      "Epoch 17/200\n",
      "26689/26689 [==============================] - 3s 101us/sample - loss: 1.0001 - mean_absolute_error: 0.4524\n",
      "Epoch 18/200\n",
      "26689/26689 [==============================] - 2s 61us/sample - loss: 1.0001 - mean_absolute_error: 0.4496\n",
      "Epoch 19/200\n",
      "26689/26689 [==============================] - 2s 79us/sample - loss: 1.0001 - mean_absolute_error: 0.4517\n",
      "Epoch 20/200\n",
      "26689/26689 [==============================] - 2s 63us/sample - loss: 1.0002 - mean_absolute_error: 0.4485\n",
      "Epoch 21/200\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0001 - mean_absolute_error: 0.4506\n",
      "Epoch 22/200\n",
      "26689/26689 [==============================] - 2s 62us/sample - loss: 1.0001 - mean_absolute_error: 0.4483\n",
      "Epoch 23/200\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0001 - mean_absolute_error: 0.4502\n",
      "Epoch 24/200\n",
      "26689/26689 [==============================] - 2s 65us/sample - loss: 1.0001 - mean_absolute_error: 0.4490\n",
      "Epoch 25/200\n",
      "26689/26689 [==============================] - 2s 64us/sample - loss: 1.0001 - mean_absolute_error: 0.4515\n",
      "Epoch 26/200\n",
      "26689/26689 [==============================] - 2s 68us/sample - loss: 1.0001 - mean_absolute_error: 0.4497\n",
      "Epoch 27/200\n",
      "26689/26689 [==============================] - 2s 64us/sample - loss: 1.0001 - mean_absolute_error: 0.4499\n",
      "Epoch 28/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0002 - mean_absolute_error: 0.4485\n",
      "Epoch 29/200\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0001 - mean_absolute_error: 0.4517\n",
      "Epoch 30/200\n",
      "26689/26689 [==============================] - 3s 98us/sample - loss: 1.0001 - mean_absolute_error: 0.4505\n",
      "Epoch 31/200\n",
      "26689/26689 [==============================] - 2s 79us/sample - loss: 1.0002 - mean_absolute_error: 0.4490\n",
      "Epoch 32/200\n",
      "26689/26689 [==============================] - 2s 83us/sample - loss: 1.0001 - mean_absolute_error: 0.4477\n",
      "Epoch 33/200\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0001 - mean_absolute_error: 0.4493\n",
      "Epoch 34/200\n",
      "26689/26689 [==============================] - 2s 89us/sample - loss: 1.0001 - mean_absolute_error: 0.4507\n",
      "Epoch 35/200\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0001 - mean_absolute_error: 0.4504\n",
      "Epoch 36/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0001 - mean_absolute_error: 0.4507\n",
      "Epoch 37/200\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0001 - mean_absolute_error: 0.4511\n",
      "Epoch 38/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0002 - mean_absolute_error: 0.4482\n",
      "Epoch 39/200\n",
      "26689/26689 [==============================] - 2s 89us/sample - loss: 1.0001 - mean_absolute_error: 0.4498\n",
      "Epoch 40/200\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0002 - mean_absolute_error: 0.4499\n",
      "Epoch 41/200\n",
      "26689/26689 [==============================] - 2s 87us/sample - loss: 1.0001 - mean_absolute_error: 0.4489\n",
      "Epoch 42/200\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0001 - mean_absolute_error: 0.4519\n",
      "Epoch 43/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0002 - mean_absolute_error: 0.4464\n",
      "Epoch 44/200\n",
      "26689/26689 [==============================] - 2s 78us/sample - loss: 1.0001 - mean_absolute_error: 0.4501\n",
      "Epoch 45/200\n",
      "26689/26689 [==============================] - 2s 82us/sample - loss: 1.0001 - mean_absolute_error: 0.4494\n",
      "Epoch 46/200\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0001 - mean_absolute_error: 0.4513\n",
      "Epoch 47/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0001 - mean_absolute_error: 0.4494\n",
      "Epoch 48/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0000 - mean_absolute_error: 0.4522\n",
      "Epoch 49/200\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0002 - mean_absolute_error: 0.4473\n",
      "Epoch 50/200\n",
      "26689/26689 [==============================] - 2s 80us/sample - loss: 1.0001 - mean_absolute_error: 0.4483\n",
      "Epoch 51/200\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0000 - mean_absolute_error: 0.4518\n",
      "Epoch 52/200\n",
      "26689/26689 [==============================] - 2s 78us/sample - loss: 1.0001 - mean_absolute_error: 0.4500\n",
      "Epoch 53/200\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0001 - mean_absolute_error: 0.4485\n",
      "Epoch 54/200\n",
      "26689/26689 [==============================] - 2s 79us/sample - loss: 1.0001 - mean_absolute_error: 0.4499\n",
      "Epoch 55/200\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0001 - mean_absolute_error: 0.4483\n",
      "Epoch 56/200\n",
      "26689/26689 [==============================] - 2s 82us/sample - loss: 1.0001 - mean_absolute_error: 0.4503\n",
      "Epoch 57/200\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0001 - mean_absolute_error: 0.4511\n",
      "Epoch 58/200\n",
      "26689/26689 [==============================] - 2s 83us/sample - loss: 1.0001 - mean_absolute_error: 0.4504\n",
      "Epoch 59/200\n",
      "26689/26689 [==============================] - 2s 82us/sample - loss: 1.0002 - mean_absolute_error: 0.4463\n",
      "Epoch 60/200\n",
      "26689/26689 [==============================] - 2s 85us/sample - loss: 1.0001 - mean_absolute_error: 0.4514\n",
      "Epoch 61/200\n",
      "26689/26689 [==============================] - 2s 88us/sample - loss: 1.0000 - mean_absolute_error: 0.4465\n",
      "Epoch 62/200\n",
      "26689/26689 [==============================] - 2s 81us/sample - loss: 1.0002 - mean_absolute_error: 0.4526\n",
      "Epoch 63/200\n",
      "26689/26689 [==============================] - 2s 83us/sample - loss: 1.0001 - mean_absolute_error: 0.4521\n",
      "Epoch 64/200\n",
      "26689/26689 [==============================] - 2s 93us/sample - loss: 1.0001 - mean_absolute_error: 0.4492\n",
      "Epoch 65/200\n",
      "26689/26689 [==============================] - 3s 99us/sample - loss: 1.0001 - mean_absolute_error: 0.4516\n",
      "Epoch 66/200\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.0001 - mean_absolute_error: 0.4493\n",
      "Epoch 67/200\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0001 - mean_absolute_error: 0.4504\n",
      "Epoch 68/200\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0001 - mean_absolute_error: 0.4499\n",
      "Epoch 69/200\n",
      "26689/26689 [==============================] - 2s 82us/sample - loss: 1.0001 - mean_absolute_error: 0.4500\n",
      "Epoch 70/200\n",
      "26689/26689 [==============================] - 2s 90us/sample - loss: 1.0001 - mean_absolute_error: 0.4509\n",
      "Epoch 71/200\n",
      "26689/26689 [==============================] - 3s 99us/sample - loss: 1.0002 - mean_absolute_error: 0.4464\n",
      "Epoch 72/200\n",
      "26689/26689 [==============================] - 3s 107us/sample - loss: 1.0001 - mean_absolute_error: 0.4513\n",
      "Epoch 73/200\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0001 - mean_absolute_error: 0.4474\n",
      "Epoch 74/200\n",
      "26689/26689 [==============================] - 2s 79us/sample - loss: 1.0001 - mean_absolute_error: 0.4517\n",
      "Epoch 75/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0001 - mean_absolute_error: 0.4506\n",
      "Epoch 76/200\n",
      "26689/26689 [==============================] - 2s 81us/sample - loss: 1.0001 - mean_absolute_error: 0.4510\n",
      "Epoch 77/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0001 - mean_absolute_error: 0.4503\n",
      "Epoch 78/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0001 - mean_absolute_error: 0.4473\n",
      "Epoch 79/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0001 - mean_absolute_error: 0.4531\n",
      "Epoch 80/200\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0002 - mean_absolute_error: 0.4493\n",
      "Epoch 81/200\n",
      "26689/26689 [==============================] - 2s 79us/sample - loss: 1.0001 - mean_absolute_error: 0.4470\n",
      "Epoch 82/200\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0001 - mean_absolute_error: 0.4528\n",
      "Epoch 83/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0002 - mean_absolute_error: 0.4490\n",
      "Epoch 84/200\n",
      "26689/26689 [==============================] - 2s 91us/sample - loss: 1.0001 - mean_absolute_error: 0.4501\n",
      "Epoch 85/200\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0002 - mean_absolute_error: 0.4490\n",
      "Epoch 86/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0001 - mean_absolute_error: 0.4488\n",
      "Epoch 87/200\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0001 - mean_absolute_error: 0.4502\n",
      "Epoch 88/200\n",
      "26689/26689 [==============================] - 2s 83us/sample - loss: 1.0001 - mean_absolute_error: 0.4475\n",
      "Epoch 89/200\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0000 - mean_absolute_error: 0.4539\n",
      "Epoch 90/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0002 - mean_absolute_error: 0.4502\n",
      "Epoch 91/200\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0001 - mean_absolute_error: 0.4505\n",
      "Epoch 92/200\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0002 - mean_absolute_error: 0.4487\n",
      "Epoch 93/200\n",
      "26689/26689 [==============================] - 2s 80us/sample - loss: 1.0001 - mean_absolute_error: 0.4515\n",
      "Epoch 94/200\n",
      "26689/26689 [==============================] - 2s 78us/sample - loss: 1.0001 - mean_absolute_error: 0.4498\n",
      "Epoch 95/200\n",
      "26689/26689 [==============================] - 2s 82us/sample - loss: 1.0001 - mean_absolute_error: 0.4488\n",
      "Epoch 96/200\n",
      "26689/26689 [==============================] - 2s 87us/sample - loss: 1.0001 - mean_absolute_error: 0.4502\n",
      "Epoch 97/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0001 - mean_absolute_error: 0.4507\n",
      "Epoch 98/200\n",
      "26689/26689 [==============================] - 2s 81us/sample - loss: 1.0001 - mean_absolute_error: 0.4526\n",
      "Epoch 99/200\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0001 - mean_absolute_error: 0.4485\n",
      "Epoch 100/200\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0001 - mean_absolute_error: 0.4498\n",
      "Epoch 101/200\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0001 - mean_absolute_error: 0.4497\n",
      "Epoch 102/200\n",
      "26689/26689 [==============================] - 2s 83us/sample - loss: 1.0001 - mean_absolute_error: 0.4508\n",
      "Epoch 103/200\n",
      "26689/26689 [==============================] - 2s 87us/sample - loss: 1.0002 - mean_absolute_error: 0.4498\n",
      "Epoch 104/200\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0001 - mean_absolute_error: 0.4508\n",
      "Epoch 105/200\n",
      "26689/26689 [==============================] - 2s 83us/sample - loss: 1.0001 - mean_absolute_error: 0.4515\n",
      "Epoch 106/200\n",
      "26689/26689 [==============================] - 3s 105us/sample - loss: 1.0002 - mean_absolute_error: 0.4480\n",
      "Epoch 107/200\n",
      "26689/26689 [==============================] - 2s 88us/sample - loss: 1.0001 - mean_absolute_error: 0.4499\n",
      "Epoch 108/200\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0000 - mean_absolute_error: 0.4513\n",
      "Epoch 109/200\n",
      "26689/26689 [==============================] - 2s 85us/sample - loss: 1.0002 - mean_absolute_error: 0.4491\n",
      "Epoch 110/200\n",
      "26689/26689 [==============================] - 3s 95us/sample - loss: 1.0001 - mean_absolute_error: 0.4495\n",
      "Epoch 111/200\n",
      "26689/26689 [==============================] - 3s 105us/sample - loss: 1.0001 - mean_absolute_error: 0.4482\n",
      "Epoch 112/200\n",
      "26689/26689 [==============================] - 3s 100us/sample - loss: 1.0001 - mean_absolute_error: 0.4517\n",
      "Epoch 113/200\n",
      "26689/26689 [==============================] - 3s 95us/sample - loss: 1.0001 - mean_absolute_error: 0.4489\n",
      "Epoch 114/200\n",
      "26689/26689 [==============================] - 3s 113us/sample - loss: 1.0000 - mean_absolute_error: 0.4520\n",
      "Epoch 115/200\n",
      "26689/26689 [==============================] - 3s 105us/sample - loss: 1.0002 - mean_absolute_error: 0.4487\n",
      "Epoch 116/200\n",
      "26689/26689 [==============================] - 3s 102us/sample - loss: 1.0001 - mean_absolute_error: 0.4502\n",
      "Epoch 117/200\n",
      "26689/26689 [==============================] - 3s 114us/sample - loss: 1.0001 - mean_absolute_error: 0.4474\n",
      "Epoch 118/200\n",
      " 4450/26689 [====>.........................] - ETA: 1s - loss: 0.8342 - mean_absolute_error: 0.4432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11836\\1218555159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0msorted_train_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_of_trips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11836\\3270986540.py\u001b[0m in \u001b[0;36msorted_train_test_split\u001b[1;34m(X, Y, test_size, model, train_model, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# train & validate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11836\\323487978.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(X_train, Y_train, X_val, Y_val, model, params)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m#verbose=params.get(\"verbose\"),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     )\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for period in time_periods:\n",
    "    for res in resolution:\n",
    "        df = prediction_data.get(period).get(res)\n",
    "        columns = get_columns(df, \"cos\")\n",
    "        nn = create_nn(len(columns), 'relu', exp_dec_func, 0.8, 1)\n",
    "        sorted_train_test_split(df[columns], df[['number_of_trips']], 0.1, nn, train_nn, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of  the different time/spaitla bin combinations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the different test/train split techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aanalyize the models with XAI methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply different NN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional NN (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent NN (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory Networks (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernalized NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare SVM and NN models in terms of predictive performance and computation time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
